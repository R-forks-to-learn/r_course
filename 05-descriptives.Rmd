# Data manipulation and descriptive statistics

Now that we are familiar with some R objects and know how to import data, it is time to actually
write some code. In this chapter, we are going to compute descriptive statistics for a single dataset,
but also for a list of datasets. However, I will not give a list of functions to compute descriptive
statistics; if you need a specific function you can find easily in the *Help* pane in Rstudio or
using any modern internet searh engine. What I will do is show you a workflow that allows you
to compute the statisics you need fast.

R has a lot of built-in functions for descriptive statistics; however, if you want to compute statistics
by, say, gender, some more complex manipulations are needed. At least this was true in the past.
Nowadays, thanks to the packages from the tidyverse (remember those we installed at the beginning
of the book?), it is very easy and fast to compute descriptive statistics by any stratifying variable(s).

The packages we are going to use for this are called `dplyr` and `tidyr`. `dplyr` contains a lot of functions that
make manipulating data and computing descriptive statistics very easy. To make things easier for now,
we are going to use example data included with `dplyr`. So no need to import an external dataset; this
does not change anything to the example that we are going to study here; the source of the data does
not matter for this. `tidyr` is very useful to reshape data. We are goig to focus on two 
functions from `tidyr`, `gather()` and `spread()`.

## Working with a single dataset

First, let's load `dplyr` and the included `starwars` dataset. Let's also take a look at the first 5
lines of the dataset:

```{r}
library(dplyr)

data(starwars)

head(starwars)
```

`data(starwars)` loads the example dataset called `starwars` that is included in the package `dplyr`.
As I said earlier, this is just an example; you could have loaded an external dataset, from a `.csv`
for instance. This does not matter for what comes next.

R includes a lot of function for descriptive statistics, such as `mean()`, `sd()`, `cov()`, and many
more. What `dplyr` brings to the table is the possibility to apply these functions to the dataset
easily. For example, imagine you want the average height of everyone in the dataset. Using the basic
R functions, you could write this:

```{r}
mean(starwars$height)
```

`starwars$height` means that the user wants to access the column called `height` from the dataset
`starwars`. This is then given as an argument to the function `mean()`. But what if the user
wants the average height by species? Before `dplyr`, a solution to this simple problem would have
required more than a single command. Now this is as easy as:

```{r}
starwars %>%
  group_by(species) %>%
  summarise(mean(height))
```

Ok, I know what you're thinking. *What the hell is this weird `%>%` thing?*. That weird thing is called the
pipe operator. What it does is take the left-hand side argument and pipe it as the first argument
of the function on the right-hand side. Try the following in the command line:

```{r}
4 %>% sqrt()
```

It is equivalent to `sqrt(4)`. Why use that though? You will see in the next examples that using the
`%>%` makes writing and reading code, much, much easier. For example, the previous manipulation I
did could be read as "Take the starwars data, give it to the `group_by()` function and then
compute the mean height". Without the `%>%`, one would need to write:

```{r}
summarise(group_by(starwars, species), mean(height))
```

as you can see, it is much more difficult to read. Imagine now that I want average height by species,
but only for males. Again, this is very easy using `%>%`:

```{r}
starwars %>%
  filter(gender == "male") %>%
  group_by(species) %>%
  summarise(mean(height))
```

Again, the `%>%` makes the above lines of code very easy to read. Without it, one would write:

```{r}
summarise(group_by(filter(starwars, gender == "male"), species), mean(height))
```

I think you agree with me that this is not very readable. Once you're used to `%>%`, you won't go
back to not use it.

To make things clearer; `filter()`, `group_by()` and `summarise()` are functions that are included
in `dplyr`. `%>%` is actually a function from `magrittr`, but this package gets loaded when you
load `dplyr` automatically, so you do not need to worry about it. `mean()` is a function *native*
to R. Another thing very nice about using `dplyr`; the result of all these operations are datasets,
or `tibbles`. This means that you can save them in variable, and then work with these as any other
datasets.

```{r}
mean_height = starwars %>%
  group_by(species) %>%
  summarise(mean(height))

class(mean_height)

head(mean_height)
```

You could then write this data to disk using `rio::export()` for instance. If you need more than the
mean of the height, you can keep adding as many functions as needed:

```{r}
summary_table = starwars %>%
  group_by(species) %>%
  summarise(ave_height = mean(height), var_height = var(height), n_obs = n())

print(summary_table)
```

I did several things there; I've added more functions, `var()` to get the variance and `n()` (which
is a function from `dplyr`, not base R) to get the number of observations. This is quite useful,
because we see that for a lot of species we only have one single individual! Let's focus on the
species for which we have more than 1 individual. Since we save all the previous operations (which
produce a `tibble`) in a variable, we can keep going from there:

```{r}
summary_table2 = summary_table %>%
  filter(n_obs > 1)

print(summary_table2)
```

There's a lot of `NA`s; this is because by default, `mean()` and `var()` return `NA` if even one single
observation is `NA` (unlike STATA). `mean()` and `var()` have a `na.rm` option that the user can set
to `TRUE` to get the result by ignoring the `NA`s:

```{r}
starwars %>%
  group_by(species) %>%
  summarise(ave_height = mean(height, na.rm = TRUE), var_height = var(height, na.rm = TRUE), n_obs = n()) %>%
  filter(n_obs > 1)
```

In the code above, I have combined the two previous steps to get the result I'm interested in. There's
a line in the final output that says `NA` for the species. Let's go back to the raw data and find
these lines:

```{r}
starwars %>%
  filter(is.na(species))
```

To test for `NA`, one uses the function `is.na()` not something like `species == "NA"` or anything
like that.`!is.na()` does the opposite:

```{r}
starwars %>%
  filter(!is.na(species))
```

The `!` function negates a predicate function (a predicate function is a function that returns
`TRUE` or `FALSE`). We can then rerun our analysis from before:

```{r}
starwars %>%
  filter(!is.na(species)) %>%
  group_by(species) %>%
  summarise(ave_height = mean(height, na.rm = TRUE), var_height = var(height, na.rm = TRUE), n_obs = n()) %>%
  filter(n_obs > 1)
```

And why not compute the same table, but adding another stratifying variable?

```{r}
starwars %>%
  filter(!is.na(species)) %>%
  group_by(species, gender) %>%
  summarise(ave_height = mean(height, na.rm = TRUE), var_height = var(height, na.rm = TRUE), n_obs = n()) %>%
  filter(n_obs > 1)
```

`dplyr` contains a lot of different functions, one of which is `mutate()`. `mutate()` allows you to
create new columns. For instance, suppose you need a column of the height of the individuals in
meters, and not in centimeters:

```{r}
starwars = starwars %>%
  mutate(height_m = height/100)

glimpse(starwars)
```

I have used `mutate()` to compute the column I need and `glimpse()` is an alternative to `print()`
that I find very useful because it shows all the columns with as many observations that fit on your
screen. We can see the column we created at the very bottom. It might be interesting to reorder the
columns; this is possible with `select()` another `dplyr` function:

```{r}
starwars = starwars %>%
  select(name, height, height_m, everything())

glimpse(starwars)
```

`select()` allows you to reorder columns by writing the order of the columns you want, and then you
can use `everything()` (another `dplyr` function) to just tell `select()` that you want everything
else in there. But `select()` also allows you to only select a subset of columns, if needed:

```{r}
starwars %>%
  select(name, height, height_m, gender) %>%
  glimpse()
```

The last thing I want to show you are the so-called *scoped* version of these functions. For
example, what if I am only interested in columns that contains text? Is there a way to select them
automatically? For this type of tasks, you can use `select_if()`:

```{r}
starwars %>%
  select_if(is.character)
```

`select_if()` selects every column that is of type character. There is also `select_all()` and
`select_at()`, each with they're own use. I will not go into more detail here. If you are
interested, I advise you read `dplyr`'s help and also the section I wrote in my other
[book](https://b-rodrigues.github.io/fput/tidyverse.html) which goes into much more detail.

### Reshaping data with `tidyr`

Another important package from the `tidyverse` that goes hand in hand with `dplyr` is `tidyr`. `tidyr`
is the package you need when it's time to reshape data. The basic functions from `tidyr`, `spread()`
and `gather()` make it possible to go from long to wide datasets respectively.

```{r}
library(tidyr)
```


## Working with a list of datasets

### Getting to know `map()`

Let's read the list of datasets from the previous chapter:

```{r}
paths = Sys.glob("datasets/unemployment/*.csv")

all_datasets = import_list(paths)

str(all_datasets)
```

For working with lists, another package from the `tidyverse` is very useful, and that would be
`purrr`. `purrr` has functions to work with lists, and we are going to focus on two of them,
`map()` and `reduce()`. `map()`... maps a function to each element of a list. `reduce()` is a bit
more complicated so we'll leave that for later.

The first thing we are going to do is use a function to clean the names of the datasets. These
names are not very easy to work with; there are spaces, and it would be better if the names of the
columns would be all lowercase. For this we are going to use the function `clean_names()` from the
`janitor` package. For a single dataset, I would write this:

```{r, include=FALSE}
library(janitor)
```

```{r, eval = FALSE}
library(janitor)

one_dataset = one_dataset %>%
  clean_names()
```

and I would get a dataset with column names in lowercase and spaces replaced by `_` (and other
corrections). How can I apply, or map, this function to each dataset in the list? To do this I need
to use `purrr::map()`:

```{r}
library(purrr)

all_datasets = all_datasets %>%
  map(clean_names)

all_datasets %>%
  glimpse()
```

So now, what if I want to know, for each dataset, which *communes* have an unemployment rate that is
less than, say, 3%? For a single dataset I would do something like this:

```{r, eval=FALSE}
one_dataset %>%
  filter(unemployment_rate_in_percent < 3)
```

But for a list of datasets, `map()` is needed (and as you will see, that is not all that is needed):

```{r}
all_datasets %>%
  map(~filter(., unemployment_rate_in_percent < 3))
```

I know what you're thinking... *what the hell?*. Let me explain: `map()` needs a function to map to
each element of the list. `all_datasets` is the list to which I want to map the function. But what
function? `filter()` is the function I need, so why doesn't:

```{r, eval = FALSE}
all_datasets %>%
  map(filter(unemployment_rate_in_percent < 3))
```
work? This is a bit complicated, and has to do with what is called environments. If you try to run
the code above, you will get this error message:

```
Error in filter(unemployment_rate_in_percent < 3) :
  object 'unemployment_rate_in_percent' not found
```

I won't go into details, but by writing `~filter(., unemployment_rate_in_percent < 3)`, which is a
formula (`~` is the symbol to define formulas, more on this in the later chapters), `map()`
converts it to a function that it can use. If you want to know more about this, you can read it in
[Advanced R](http://adv-r.had.co.nz/Functional-programming.html#closures) by Hadley Wickham, but it
is an advanced topic.


### Getting to know `reduce()`

Using `map()` we now know how to apply a function to each dataset of a list. But maybe it would be
easier to merge all the datasets first, and then manipulate them? Before that though, I am going to
teach you how to use `purrr::reduce()`, another very powerful function that works on lists. This is
a function that you can find in other programming languages, but sometimes it is called fold.

I think that the following example illustrates the power of `reduce()` well:

```{r}
numbers = seq(1, 5) # Create a vector with the numbers 1 to 5

reduce(numbers, `+`, .init = 0)
```

`reduce()` takes a function as an argument, here the function `+`^[This is simply the `+` operator
you're used to. Try this out: `` `+`(1, 5) `` and you'll see `+` is a function like any other. You
just have to write backticks around the plus symbol to make it work.] and then does the following
computation:

```
0 + numbers[1] + numbers[2] + numbers[3]...
```

It applies the user supplied function successively but has to start with something, so we give it
the argument `init` also. This argument is actually optional, but I show it here because in some
cases it might be useful to start the computations at another value than `0`.`reduce()`
generalizes functions that only take two arguments. If you were to write a function that returns
the minimum between two numbers:

```{r}
my_min = function(a, b){
    if(a < b){
        return(a)
    } else {
        return(b)
    }
}
```

You could use `reduce()` to get the minimum of a list of numbers:

```{r}
numbers2 = c(3, 1, -8, 9)

reduce(numbers2, my_min)
```

As long as you provide a function and a list of elements to `reduce()`, you will get a single
output. So how could `reduce()` help us with merging all the datasets that are in the list? `dplyr`
comes with a lot of function to merge *two* datasets. Remember that I said before that `reduce()`
allows you to generalize a function of two arguments? Let's try it with our list of datasets:


```{r}
unemp_lux = reduce(all_datasets, full_join)

glimpse(unemp_lux)
```

`full_join()` is one of the `dplyr` function that merges data. There are others that might be
useful depending on the kind of join operation you need. Let's write this data to disk as we're
going to keep using it for the next chapters:

```{r}
export(unemp_lux, "datasets/unemp_lux.csv")
```

## List-columns

To learn about list-columns, let's first focus on a single character of the `starwars` dataset:

```{r}
data(starwars)
```

```{r}
starwars %>%
  filter(name == "Luke Skywalker") %>%
  glimpse()
```

We see that the columns `films`, `vehicles` and `starships` are all lists, and in the case of 
`films`, it lists all the films where Luke Skywalker has appeared. What if you want to take a closer look at this list?

```{r}
starwars %>%
  filter(name == "Luke Skywalker") %>%
  pull(films)
```

`pull()` is a `dplyr` function that extract (pulls) the column you're interested in. It is quite
useful when you want to inspect a column. 

Suppose we want to create a categorical variable which counts the number of movies in which the
characters have appeared. For this we need to compute the length of the list, or count the number
of elements this list has. Let's try with `length()` a base R function:

```{r}
starwars %>%
  filter(name == "Luke Skywalker") %>%
  pull(films) %>%
  length()
```

This might be surprising at first, because we know that Luke Skywalker has appeared in more than 1
movie... the problem here is that for each individual, `films` is a list, whose single element is 
a vector of characters. This means that `length(films)` computes the length of the list, which is
one, and not the length of the vector contained in the list! How can we get the length of the
vector of characters contained in the list and for each character? For this we need to use
`dplyr::rowwise()` and remove the `filter()` function and use `mutate()` to add this column to the
dataset:


```{r}
starwars = starwars %>%
  rowwise() %>%
  mutate(n_films = length(films)) 
```

`dplyr::rowwise()` is useful when working with list-columns: columns that have lists as elements.

Let's take a look at the characters and the number of films they have appeared in:

```{r}
starwars %>% 
  select(name, n_films)
```

Now we can create a factor variable that groups characters by asking whether they appeared only 1
movie, or more:

```{r}
starwars = starwars %>%
  mutate(more_1 = case_when(n_films == 1 ~ "Exactly one movie",
                            n_films != 1 ~ "More than 1 movie"))
```


List columns are very useful, and we will look more into them in the coming chapters.
