[
["index.html", "Modern R for STATEC Preface What is R? Why modern R? What is Rstudio? Prerequisites What are packages?", " Modern R for STATEC Bruno Rodrigues 2017-10-26 Preface What is R? Read R’s official answer to this question here. To make it short: R is multi-paradigm (procedural, imperative, object-oriented and functional)1 programming language that focuses on applications in statistics. By statistics I mean any field that uses statistics such as official statistics, economics, finance, data science, etc. Why modern R? Modern R instead of just R because we are going to learn how to use modern packages and concepts, such as functional programming (which is quite an old concept actually, but one that came into fashion recently). R is derived from S, which is a programming language that has roots in FORTRAN and Scheme. If you learned R at university, you’ve probably learned to use it as you would have used FORTRAN; very long scripts where data are represented as matrices and where row-wise (or column-wise) operations are implemented with for loops. There’s nothing wrong with that, mind you, but it is a shame not to use R’s functional programming capabilities that it inherited from Scheme, because I believe that it makes writing code easier and more natural. At its core, functional programming uses functions, and functions are first class objects in R. We are going to learn what that means later. First, we are going to use functions that are already available in R, and then use those available in packages, mostly those from the tidyverse. The tidyverse is a collection of packages developed by Hadley Wickham. By using the packages from the tidyverse and R’s built-in functional programming capabilities, we can write code that is faster and easier to explain to colleagues, and also easier to maintain. This also means that you might have to change your expectations and what you know already from R, if you learned it at University but haven’t touched it in a long time. What is Rstudio? Rstudio is a modern IDE that makes writing R code easier. The first thing we are going to learn is how to use it. R and Rstudio are both open source: this means that the source code is freely available on the internet and contributions by anyone are welcome and integrated; provided they are meaningful and useful. Prerequisites R and Rstudio are the two main pieces of software that we are going to use. Both are already installed on your desktop computer. R is the programming language and Rstudio is a modern IDE for it. You can use R without Rstudio; but you cannot use Rstudio without R. If you wish to install R and Rstudio at home to follow the examples in this book you can do it as both pieces of software are available free of charge (for firms paid options for Rstudio exist). Installation is simple, but operating system dependent. To download and install R for Windows, follow this link. For macOS, follow this one. If you run a GNU+Linux distribution, you can install R using the system’s package manager. On Ubuntu, install r-base. For Rstudio, look for your operating system here. What are packages? There is one more step; we are going to install some packages. Packages are additional pieces of code that can be installed from within R with the following function: install.packages(). These packages extend R’s capabilities significantly, and are probably one of the main reasons R is so popular. As of October 2017, R has over 11000 packages. To install the packages we need, first open Rstudio and then copy and paste this line in the console: install.packages(c(&quot;tidyverse&quot;, &quot;checkpoint&quot;, &quot;Ecdat&quot;, &quot;ggthemes&quot;, &quot;janitor&quot;, &quot;rio&quot;, &quot;colourpicker&quot;)) or go to the Packages pane and then click on Install: The author My name is Bruno Rodrigues and I work in the research department of STATEC. I program almost exclusively in R and have been teaching some R courses for a few years now (first started teaching for students at the Université of Strasbourg). These notes are an update of those I used at the time, plus a lot of things I’ve learned about R since I started working at STATEC. I also am writing another book that is more advanced than this one. In my free time I like cooking, boxing and blogging. You can follow me on twitter if you’d like! In this book we are going to focus on R’s functional programming capabilities↩ "],
["getting-to-know-rstudio.html", "Chapter 1 Getting to know Rstudio 1.1 Panes 1.2 Console 1.3 Scripts 1.4 Options 1.5 Keyboard shortcuts 1.6 Projects 1.7 History 1.8 Plots", " Chapter 1 Getting to know Rstudio 1.1 Panes Rstudio is divided into different panes. Each pane has a specific function. The gif below shows some of these panes: Take some time to look around what each pane shows you. Some panes are empty; for example the Plots pane or the Viewer pane. Plots shows you the plots you make. You can browse the plots and save them. We will see this in more detail in a later chapter. Viewer shows you previews of documents that you generate with R. More on this later. 1.2 Console The Console pane is where you can execute R code. Write the following in the console: 2 + 3 and you’ll get the answer, 5. However, do not write a lot of lines in the console. It is better write your code inside a script. 1.3 Scripts Look at the gif below: In this gif, we see the user creating a new R script. R scripts are simple text files that hold R code. Think of .do files in STATA or .c files for C. R scripts have the extension .r or .R. It is possible to create a lot of other files. We’ll take a look at R Markdown files later. 1.3.1 The help pane The Help pane allows you to consult documentation for functions or packages. The gif below shows how it works: you can also access help using the following syntax: ?lm. This will bring up the documentation for the function lm(). You can also type ??lm which will look for the string lm in every package. 1.3.2 The Environment pane The Environment pane shows every object created in the current section. It is especially useful if you have defined lists or have loaded data into R as it makes it easy to explore these more complex objects. 1.4 Options It is also possible to customize Rstudio’s look and feel: Take some time to go through the options. 1.5 Keyboard shortcuts It is a good idea to familiarize yourself with at least some keyboard shortcuts. This is more convenient than having to move the mouse around: If there is only one keyboard shortcut you need to know, it’s Ctrl-Enter that executes a line of code from your script. However, these other shortcuts are also worth knowing: CTRL-ALT-R: run entire script CTRL-ALT-UP or DOWN: make cursor taller or shorter, allowing you to edit multiple lines at the same time CTRL-F: Search and replace ALT-UP or DOWN: Move line up or down CTRL-SHIFT-C: Comment/uncomment line ALT-SHIFT-K: Bring up the list of keyboard shortcuts CTRL-SHIFT-M: Insert the pipe operator (%&gt;%, more on this later) CTRL-S: Save script This is just a few keyboard shortcuts that I personally find useful. However, I strongly advise you to learn and use whatever shortcuts are useful to you! 1.6 Projects One of the best features of Rstudio are projects. Creating a project is simple; the gif below shows how you can create a project and how you can switch between projects. Projects make a lot of things easier, such as managing paths. More on this in the chapter about reading data. Another useful feature of projects is that the scripts you open in project A will stay open even if you switch to another project B, and then switch back to the project A again. You can also use version control (with git) inside a project. Version control is very useful, but I won’t discuss it here. You can find a lot of resources online to get you started with git. 1.7 History The history pane saves all the previous lines you executed. You can then select these lines and send them back to the console or the script. 1.8 Plots All the plots you make during a session are visible in the Plots pane. From there, you can export them in different formats. The plots shown in the gif are made using basic R functions. Later, we will learn how to make nicer looking plots using the package ggplot2. "],
["packages.html", "Chapter 2 Packages", " Chapter 2 Packages You can think of packages as addons that extend R’s core functionality. You can browse all available packages on CRAN. To make it easier to find what you might be interested in, you can also browse the CRAN Task Views. Each package has a landing page that summarises its dependencies, version number etc. For example, for the dplyr package: https://cran.r-project.org/web/packages/dplyr/index.html. Take a look at the Downloads section, and especially at the Reference Manual and Vignettes: Vignettes are valuable documents; inside vignettes, the purpose of the package is explained in plain English, usually with accompanying examples. The reference manuals list the available functions inside the packages. You can also find vignettes from within Rstudio: Go to the Packages pane and click on the package you’re interested in. Then you can consult the help for the functions that come with the package as well as the package’s vignettes. Once you installed a package, you have to load it before you can use it. To load packages you use the library() function: library(dplyr) library(janitor) # and so on... If you only need to use one single function once, you don’t need to load an entire package. You can write the following: dplyr::full_join(A, B) using the :: operator, you can access functions from packages without having to load the whole package beforehand. It is possible and easy to create your own packages. This is useful if you have to write a lot of functions that you use daily. This is outside the scope of this book, but if you’re interested you can read this other one I wrote. "],
["data-types-and-objects.html", "Chapter 3 Data types and objects 3.1 The numeric class 3.2 The character class 3.3 Vectors and matrices 3.4 The logical class 3.5 The list class 3.6 The data.frame and tibble classes 3.7 Formulas 3.8 Exercises", " Chapter 3 Data types and objects R use a variety of data types. You already know most of them, actually! Integers (), floating point numbers, or floats (), matrices, etc, are all objects you already use on a daily basis. But R has a lot of other data types (that you can find in a lot of other programming languages) that you need to become familiar with. But first, we need to learn how to assign a variable. This can be done in two ways: a &lt;- 3 or a = 3 there is almost no difference between these two approaches. You would need to pay attention to this, and use &lt;- in very specific situations to which you will very likely never be confronted to. Another thing you must know is that you can convert from one type to another using as.character(), as.numeric(), as.logical(), etc… For example, as.character(1) converts the number 1 to the character (or string) “1”. There are also is.character(), is.numeric() and so on that test if the object is of the required class. These functions exist for each object type, and are very useful. Make sure you remember them! 3.1 The numeric class To define single numbers, you can do the following: a = 3 The class() function allows you to check the class of an object: class(a) ## [1] &quot;numeric&quot; Decimals are defined with the character `.}: a = 3.14 3.2 The character class Use &quot; &quot; to define characters (called strings in other programming languages): a = &quot;this is a string&quot; class(a) ## [1] &quot;character&quot; 3.3 Vectors and matrices You can create a vector in different ways. But first of all, it is important to understand that a vector in most programming languages is nothing more than a list of things. These things can be numbers (either integers or floats), strings, or even other vectors. The same applies for matrices. 3.3.1 The c() function A very important function that allows you to build a vector is c(): a = c(1,2,3,4,5) This creates a vector with elements 1, 2, 3, 4, 5. If you check its class: class(a) ## [1] &quot;numeric&quot; This can be confusing: you where probably expecting a to be of class or something similar. This is not the case if you use c() to create the vector, because c() doesn’t build a vector in the mathematical sense, but rather a list with numbers. Checking its dimension: dim(a) ## NULL A list doesn’t have a dimension, that’s why the dim() command returns NULL. If you want to create a true vector, you need to use cbind() or rbind(). 3.3.2 cbind() and rbind() You can create a true vector with cbind(): a = cbind(1,2,3,4,5) Check its class now: class(a) ## [1] &quot;matrix&quot; This is exactly what we expected. Let’s check its dimension: dim(a) ## [1] 1 5 This returns the dimension of a using the LICO notation (number of LInes first, the number of COlumns). It is also possible to bind vectors together to create a matrix. b = cbind(6,7,8,9,10) Now let’s put vector a and b into a matrix called matrix_c using rbind(). rbind() functions the same way as cbind() but glues the vectors together by rows and not by columns. matrix_c = rbind(a,b) print(matrix_c) ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 2 3 4 5 ## [2,] 6 7 8 9 10 3.3.3 The matrix class R also has support for matrices. For example, you can create a matrix of dimension (5,5) filled with 0’s with the matrix() function: matrix_a = matrix(0, nrow = 5, ncol = 5) If you want to create the following matrix: \\[ B = \\left( \\begin{array}{ccc} 2 &amp; 4 &amp; 3 \\\\ 1 &amp; 5 &amp; 7 \\end{array} \\right) \\] you would do it like this: B = matrix(c(2, 4, 3, 1, 5, 7), nrow = 2, byrow = TRUE) The option byrow = TRUE means that the rows of the matrix will be filled first. You can access individual elements of matrix_a like so: matrix_a[2, 3] ## [1] 0 and R returns its value, 0. We can assign a new value to this element if we want. Try: matrix_a[2, 3] = 7 and now take a look at matrix_a again. print(matrix_a) ## [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 7 0 0 ## [3,] 0 0 0 0 0 ## [4,] 0 0 0 0 0 ## [5,] 0 0 0 0 0 Recall our vector b: b = cbind(6,7,8,9,10) To access its third element, you can simply write: b[3] ## [1] 8 3.4 The logical class This class is the result of logical comparisons, for example, if you type: 4 &gt; 3 ## [1] TRUE R returns true. If we save this in a variable l: l = 4 &gt; 3 and check l’s class: class(l) ## [1] &quot;logical&quot; R returns logical. In other programming languages, logicals are often called bools. A logical variable can only have two values, either TRUE or FALSE. 3.5 The list class The list class is a very flexible class, and thus, very useful. You can put anything inside a list, such as numbers: list1 = list(3, 2) or vectors: list2 = list(c(1, 2), c(3, 4)) you can also put objects of different classes in the same list: list3 = list(3, c(1, 2), &quot;lists are amazing!&quot;) and of course create list of lists: my_lists = list(list1, list2, list3) To check the contents of a list, you can use the structure function str(): str(my_lists) ## List of 3 ## $ :List of 2 ## ..$ : num 3 ## ..$ : num 2 ## $ :List of 2 ## ..$ : num [1:2] 1 2 ## ..$ : num [1:2] 3 4 ## $ :List of 3 ## ..$ : num 3 ## ..$ : num [1:2] 1 2 ## ..$ : chr &quot;lists are amazing!&quot; or you can use Rstudio’s Environment pane: You can also create named lists: list4 = list(&quot;a&quot; = 2, &quot;b&quot; = 8, &quot;c&quot; = &quot;this is a named list&quot;) and you can access the elements in two ways: list4[[1]] ## [1] 2 or, for named lists: list4$c ## [1] &quot;this is a named list&quot; Lists are used extensively because they are so flexible. You can build lists of datasets and apply functions to all the datasets at once, build lists of models, lists of plots, etc… In the later chapters we are going to learn all about them. 3.6 The data.frame and tibble classes In the next chapter we are going to learn how to import datasets into R. Once you import data, the resulting object is either a data.frame or a tibble depending on which package you used to import the data. tibbles extend data.frames so if you know about data.frame objects already, working with tibbles will be very easy. tibbles have a better print() method, and some other niceties. If you want to know more, I go into more detail in my other book but for our purposes, there’s not much you need to know about data.frame and tibble objects, apart that this is the representation of a dataset when loaded into R. However, I want to stress that these objects are central to R and are thus very important. There are different ways to print a data.frame or a tibble if you wish to inspect it. You can use View(my_data) to show the my_data data.frame in the View pane of RStudio: You can also use the str() function: str(my_data) And if you need to access an individual column, you can use the $ sign, same as for a list: my_data$col1 3.7 Formulas We will learn more about formulas later, but because it is an important object, it is useful if you already know about them early on. A formula is defined in the following way: my_formula = ~x class(my_formula) ## [1] &quot;formula&quot; Formula objects are defined using the ~ symbol. Formulas are useful to define statistical models, for example for a linear regression: lm(y ~ x) or also to define anonymous functions, but more on this later. 3.8 Exercises Exercise 1 Try to create the following vector: \\[a = (6,3,8,9)\\] and add it this other vector: \\[b = (9,1,3,5)\\] and save the result to a new variable called result. 3.8.1 Exercise 2 Using a and b from before, try to get their dot product. Try with a * b in the R console. What happened? Try to find the right function to get the dot product. Don’t hesitate to google the answer! 3.8.2 Exercise 3 How can you create a matrix of dimension (30,30) filled with 2’s by only using the function matrix()? 3.8.3 Exercise 4 Save your first name in a variable a and your surname in a variable b. What does the function: paste(a,b) do? Look at the help for paste() with ?paste or using the Help pane in Rstudio. What does the optional argument sep do? 3.8.4 Exercise 5 Define the following variables: a = 8, b = 3, c = 19. What do the following lines check? What do they return? a &gt; b a == b a != b a &lt; b (a &gt; b) &amp;&amp; (a &lt; c) (a &gt; b) &amp;&amp; (a &gt; c) (a &gt; b) || (a &lt; b) 3.8.5 Exercise 6 Define the following matrix: \\[ \\text{matrix_a} = \\left( \\begin{array}{ccc} 9 &amp; 4 &amp; 12 \\\\ 5 &amp; 0 &amp; 7 \\\\ 2 &amp; 6 &amp; 8 \\\\ 9 &amp; 2 &amp; 9 \\end{array} \\right) \\] What does matrix_a &gt;= 5 do? What does matrix_a[ , 2] do? Can you find which function gives you the transpose of this matrix? 3.8.6 Exercise 7 Solve the following system of equations using the solve() function: \\[ \\left( \\begin{array}{cccc} 9 &amp; 4 &amp; 12 &amp; 2 \\\\ 5 &amp; 0 &amp; 7 &amp; 9\\\\ 2 &amp; 6 &amp; 8 &amp; 0\\\\ 9 &amp; 2 &amp; 9 &amp; 11 \\end{array} \\right) \\times \\left( \\begin{array}{ccc} x \\\\ y \\\\ z \\\\ t \\\\ \\end{array}\\right) = \\left( \\begin{array}{ccc} 7\\\\ 18\\\\ 1\\\\ 0 \\end{array} \\right) \\] "],
["reading-and-writing-data.html", "Chapter 4 Reading and writing data 4.1 The swiss army knife of data import and export: rio 4.2 Writing any object to disk", " Chapter 4 Reading and writing data In this chapter, we are going to import example datasets that are available in R, mtcars and iris. I have converted these datasets into several formats. Download those datasets here if you want to follow the examples below. R can import some formats without the need of external packages, such as the .csv format. However, for other formats, you will need to use different packages. Because there are a lot of different formats available I suggest you use rio. rio is basically a wrapper around a lot of packages that exist to import/export data. This package is nice because you don’t need to remember which package to use to import, say, STATA datasets and then you need to remember which one for SAS datasets, and so on. Read rio’s vignette for more details. Below I show some of rio’s functions presented in the vignette. It is also possible to import data from other, less “traditional” sources, such as your clipboard. 4.1 The swiss army knife of data import and export: rio To import data with rio, import() is all you need: library(rio) mtcars = import(&quot;datasets/mtcars.csv&quot;) head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## 2 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## 3 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## 4 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## 5 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## 6 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 import() needs the path to the data, and you can specify additional options if needed. On a Windows computer, you have to be careful to the path; you cannot simply copy and paste it, because paths in Windows use the \\ symbol whereas R uses / (just like on Linux or macOS). Importing a STATA or a SAS file is done just the same: mtcars_stata = import(&quot;datasets/mtcars.dta&quot;) head(mtcars_stata) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## 2 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## 3 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## 4 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## 5 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## 6 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 mtcars_sas = import(&quot;datasets/mtcars.sas7bdat&quot;) head(mtcars_sas) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## 2 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## 3 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## 4 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## 5 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## 6 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 It is also possible to import Excel files where each sheet is a single table, but you will need import_list() for that. The file multi.xlsx has two sheets, each with a table in it: multi = import_list(&quot;datasets/multi.xlsx&quot;) str(multi) ## List of 2 ## $ :&#39;data.frame&#39;: 32 obs. of 11 variables: ## ..$ mpg : num [1:32] 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... ## ..$ cyl : num [1:32] 6 6 4 6 8 6 8 4 4 6 ... ## ..$ disp: num [1:32] 160 160 108 258 360 ... ## ..$ hp : num [1:32] 110 110 93 110 175 105 245 62 95 123 ... ## ..$ drat: num [1:32] 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... ## ..$ wt : num [1:32] 2.62 2.88 2.32 3.21 3.44 ... ## ..$ qsec: num [1:32] 16.5 17 18.6 19.4 17 ... ## ..$ vs : num [1:32] 0 0 1 1 0 1 0 1 1 1 ... ## ..$ am : num [1:32] 1 1 1 0 0 0 0 0 0 0 ... ## ..$ gear: num [1:32] 4 4 4 3 3 3 3 4 4 4 ... ## ..$ carb: num [1:32] 4 4 1 1 2 1 4 2 2 4 ... ## $ :&#39;data.frame&#39;: 150 obs. of 5 variables: ## ..$ Sepal.Length: num [1:150] 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## ..$ Sepal.Width : num [1:150] 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## ..$ Petal.Length: num [1:150] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## ..$ Petal.Width : num [1:150] 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## ..$ Species : chr [1:150] &quot;setosa&quot; &quot;setosa&quot; &quot;setosa&quot; &quot;setosa&quot; ... As you can see multi is a list of datasets. Told you lists were very flexible! It is also possible to import all the datasets in a single directory at once. For this, you first need a vector of paths: paths = Sys.glob(&quot;datasets/unemployment/*.csv&quot;) Sys.glob() allows you to find files using a regular expression. “datasets/unemployment/*.csv&quot; matches all the .csv files inside “datasets/unemployment”. all_data = import_list(paths) str(all_data) ## List of 4 ## $ :&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ Commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ Total employed population : int [1:118] 223407 17802 1703 844 1431 4094 2146 971 1218 3002 ... ## ..$ of which: Wage-earners : int [1:118] 203535 15993 1535 750 1315 3800 1874 858 1029 2664 ... ## ..$ of which: Non-wage-earners: int [1:118] 19872 1809 168 94 116 294 272 113 189 338 ... ## ..$ Unemployed : int [1:118] 19287 1071 114 25 74 261 98 45 66 207 ... ## ..$ Active population : int [1:118] 242694 18873 1817 869 1505 4355 2244 1016 1284 3209 ... ## ..$ Unemployment rate (in %) : num [1:118] 7.95 5.67 6.27 2.88 4.92 ... ## ..$ Year : int [1:118] 2013 2013 2013 2013 2013 2013 2013 2013 2013 2013 ... ## $ :&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ Commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ Total employed population : int [1:118] 228423 18166 1767 845 1505 4129 2172 1007 1268 3124 ... ## ..$ of which: Wage-earners : int [1:118] 208238 16366 1606 757 1390 3840 1897 887 1082 2782 ... ## ..$ of which: Non-wage-earners: int [1:118] 20185 1800 161 88 115 289 275 120 186 342 ... ## ..$ Unemployed : int [1:118] 19362 1066 122 19 66 287 91 38 61 202 ... ## ..$ Active population : int [1:118] 247785 19232 1889 864 1571 4416 2263 1045 1329 3326 ... ## ..$ Unemployment rate (in %) : num [1:118] 7.81 5.54 6.46 2.2 4.2 ... ## ..$ Year : int [1:118] 2014 2014 2014 2014 2014 2014 2014 2014 2014 2014 ... ## $ :&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ Commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ Total employed population : int [1:118] 233130 18310 1780 870 1470 4130 2170 1050 1300 3140 ... ## ..$ of which: Wage-earners : int [1:118] 212530 16430 1620 780 1350 3820 1910 920 1100 2770 ... ## ..$ of which: Non-wage-earners: int [1:118] 20600 1880 160 90 120 310 260 130 200 370 ... ## ..$ Unemployed : int [1:118] 18806 988 106 29 73 260 80 41 72 169 ... ## ..$ Active population : int [1:118] 251936 19298 1886 899 1543 4390 2250 1091 1372 3309 ... ## ..$ Unemployment rate (in %) : num [1:118] 7.46 5.12 5.62 3.23 4.73 ... ## ..$ Year : int [1:118] 2015 2015 2015 2015 2015 2015 2015 2015 2015 2015 ... ## $ :&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ Commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ Total employed population : int [1:118] 236100 18380 1790 870 1470 4160 2160 1030 1330 3150 ... ## ..$ of which: Wage-earners : int [1:118] 215430 16500 1640 780 1350 3840 1900 900 1130 2780 ... ## ..$ of which: Non-wage-earners: int [1:118] 20670 1880 150 90 120 320 260 130 200 370 ... ## ..$ Unemployed : int [1:118] 18185 975 91 27 66 246 76 35 70 206 ... ## ..$ Active population : int [1:118] 254285 19355 1881 897 1536 4406 2236 1065 1400 3356 ... ## ..$ Unemployment rate (in %) : num [1:118] 7.15 5.04 4.84 3.01 4.3 ... ## ..$ Year : int [1:118] 2016 2016 2016 2016 2016 2016 2016 2016 2016 2016 ... in a subsequent chapter we will learn how to actually use these lists of datasets. If something goes wrong, you might need to take a look at the underlying function rio is actually using to import the file. Let’s look at the following example: testdata = import(&quot;datasets/problems/mtcars.csv&quot;) head(testdata) ## mpg&amp;cyl&amp;disp&amp;hp&amp;drat&amp;wt&amp;qsec&amp;vs&amp;am&amp;gear&amp;carb ## 1 21&amp;6&amp;160&amp;110&amp;3.9&amp;2.62&amp;16.46&amp;0&amp;1&amp;4&amp;4 ## 2 21&amp;6&amp;160&amp;110&amp;3.9&amp;2.875&amp;17.02&amp;0&amp;1&amp;4&amp;4 ## 3 22.8&amp;4&amp;108&amp;93&amp;3.85&amp;2.32&amp;18.61&amp;1&amp;1&amp;4&amp;1 ## 4 21.4&amp;6&amp;258&amp;110&amp;3.08&amp;3.215&amp;19.44&amp;1&amp;0&amp;3&amp;1 ## 5 18.7&amp;8&amp;360&amp;175&amp;3.15&amp;3.44&amp;17.02&amp;0&amp;0&amp;3&amp;2 ## 6 18.1&amp;6&amp;225&amp;105&amp;2.76&amp;3.46&amp;20.22&amp;1&amp;0&amp;3&amp;1 as you can see, the import didn’t work quite well! This is because the separator is the &amp; for some reason. Because we are trying to read a .csv file, rio::import() is trying to use data.table::fread() under the hood (you can read this in imports()’s help). If you go and read data.table::fread()’s help, you see that the fread() has an optional sep = argument that you can use to specify the separator. You can use this argument in import() too, and it will be passed down to fread(): testdata = import(&quot;datasets/problems/mtcars.csv&quot;, sep = &quot;&amp;&quot;) head(testdata) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## 2 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## 3 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## 4 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## 5 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## 6 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 export() allows you to write data to disk, by simply providing the path and name of the file you wish to save. export(testdata, &quot;path/where/to/save/testdata.csv&quot;) If you end the name with .csv the file is exported to the csv format, if instead you write .dta the data will be exported to the STATA format, etc. If you wish to export to Excel, this is possible, but requires that you change a file on your computer (you only have to do this once). Run the following lines in Rstudio: if(!file.exists(&quot;~/.Rprofile&quot;)) # only create if not already there file.create(&quot;~/.Rprofile&quot;) # (don&#39;t overwrite it) file.edit(&quot;~/.Rprofile&quot;) These lines, taken shamelessly from Efficient R programming (go read it, it’s a very great resource) look for and open the .Rprofile file which is a file that is run every time you open Rstudio. This means that you can put any line of code there that will always be executed whenever you launch Rstudio. The line you need to add is this: Sys.setenv(&quot;R_ZIPCMD&quot; = &quot;C:/Program Files (x86)/Rtools/zip.exe&quot;) This tells Rstudio to use zip.exe as the default zip tool, which is needed to export files to the Excel format. Try it out by restarting Rstudio, and then running the following lines: library(rio) data(mtcars) export(mtcars, &quot;mtcars.xlsx&quot;) You should find the mtcars.xlsx inside your working directory (it should be your Documents folder. You can use getwd() to check where you are). rio should cover all your needs, but if not, there is very likely a package out there that will import the data you need. 4.2 Writing any object to disk rio is an amazing package, but is only able to write tabular representations of data. What if you would like to save, say, a list containing any arbitrary object? This is possible with the saveRDS() function. Literally anything can be saved with saveRDS(): my_list = list(&quot;this is a list&quot;, list(&quot;which contains a list&quot;, 12), c(1, 2, 3, 4), matrix(c(2, 4, 3, 1, 5, 7), nrow = 2)) str(my_list) ## List of 4 ## $ : chr &quot;this is a list&quot; ## $ :List of 2 ## ..$ : chr &quot;which contains a list&quot; ## ..$ : num 12 ## $ : num [1:4] 1 2 3 4 ## $ : num [1:2, 1:3] 2 4 3 1 5 7 my_list is a list containing a string, a list which contains a string and a number, a vector and a matrix… Now suppose that computing this list takes a very long time (for example, imagine that each element of the list is the result of estimating a very complex model on a particular simulated dataset for instance) and you would like to save this list to disk. This is possible with saveRDS(): saveRDS(my_list, &quot;my_list.RDS&quot;) The next day, after having freshly started your computer and launched RStudio, it is possible to retrieved the object exactly like it was using readRDS(): my_list = readRDS(&quot;my_list.RDS&quot;) str(my_list) ## List of 4 ## $ : chr &quot;this is a list&quot; ## $ :List of 2 ## ..$ : chr &quot;which contains a list&quot; ## ..$ : num 12 ## $ : num [1:4] 1 2 3 4 ## $ : num [1:2, 1:3] 2 4 3 1 5 7 Even if you want to save a regular dataset, using saveRDS() might be a good idea because the data gets compressed if you add the option compress = TRUE to saveRDS(). However keep in mind that this will only be readable by R, so if you need to share this data with colleagues that use another tool, save it in another format. "],
["data-manipulation-and-descriptive-statistics.html", "Chapter 5 Data manipulation and descriptive statistics 5.1 Working with a single dataset 5.2 Working with a list of datasets 5.3 List-columns", " Chapter 5 Data manipulation and descriptive statistics Now that we are familiar with some R objects and know how to import data, it is time to actually write some code. In this chapter, we are going to compute descriptive statistics for a single dataset, but also for a list of datasets. However, I will not give a list of functions to compute descriptive statistics; if you need a specific function you can find easily in the Help pane in Rstudio or using any modern internet search engine. What I will do is show you a workflow that allows you to compute the statisics you need fast. R has a lot of built-in functions for descriptive statistics; however, if you want to compute statistics by, say, gender, some more complex manipulations are needed. At least this was true in the past. Nowadays, thanks to the packages from the tidyverse (remember those we installed at the beginning of the book?), it is very easy and fast to compute descriptive statistics by any stratifying variable(s). The packages we are going to use for this are called dplyr and tidyr. dplyr contains a lot of functions that make manipulating data and computing descriptive statistics very easy. To make things easier for now, we are going to use example data included with dplyr. So no need to import an external dataset; this does not change anything to the example that we are going to study here; the source of the data does not matter for this. tidyr is very useful to reshape data. We are going to focus on two functions from tidyr, gather() and spread(). 5.1 Working with a single dataset 5.1.1 Manipulating and creating columns with dplyr First, let’s load dplyr and the included starwars dataset. Let’s also take a look at the first 5 lines of the dataset: library(dplyr) data(starwars) head(starwars) ## # A tibble: 6 x 13 ## name height mass hair_color skin_color eye_color birth_year ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Luke Skywalker 172 77 blond fair blue 19.0 ## 2 C-3PO 167 75 &lt;NA&gt; gold yellow 112.0 ## 3 R2-D2 96 32 &lt;NA&gt; white, blue red 33.0 ## 4 Darth Vader 202 136 none white yellow 41.9 ## 5 Leia Organa 150 49 brown light brown 19.0 ## 6 Owen Lars 178 120 brown, grey light blue 52.0 ## # ... with 6 more variables: gender &lt;chr&gt;, homeworld &lt;chr&gt;, species &lt;chr&gt;, ## # films &lt;list&gt;, vehicles &lt;list&gt;, starships &lt;list&gt; data(starwars) loads the example dataset called starwars that is included in the package dplyr. As I said earlier, this is just an example; you could have loaded an external dataset, from a .csv for instance. This does not matter for what comes next. R includes a lot of function for descriptive statistics, such as mean(), sd(), cov(), and many more. What dplyr brings to the table is the possibility to apply these functions to the dataset easily. For example, imagine you want the average height of everyone in the dataset. Using the basic R functions, you could write this: mean(starwars$height) ## [1] NA starwars$height means that the user wants to access the column called height from the dataset starwars. This is then given as an argument to the function mean(). But what if the user wants the average height by species? Before dplyr, a solution to this simple problem would have required more than a single command. Now this is as easy as: starwars %&gt;% group_by(species) %&gt;% summarise(mean(height)) ## # A tibble: 38 x 2 ## species `mean(height)` ## &lt;chr&gt; &lt;dbl&gt; ## 1 Aleena 79.0000 ## 2 Besalisk 198.0000 ## 3 Cerean 198.0000 ## 4 Chagrian 196.0000 ## 5 Clawdite 168.0000 ## 6 Droid NA ## 7 Dug 112.0000 ## 8 Ewok 88.0000 ## 9 Geonosian 183.0000 ## 10 Gungan 208.6667 ## # ... with 28 more rows Ok, I know what you’re thinking. What the hell is this weird %&gt;% thing? That weird thing is called the pipe operator. What it does is take the left-hand side argument and pipe it as the first argument of the function on the right-hand side. Try the following in the command line: 4 %&gt;% sqrt() ## [1] 2 It is equivalent to sqrt(4). Why use that though? You will see in the next examples that using the %&gt;% makes writing and reading code, much, much easier. For example, the previous manipulation I did could be read as “Take the starwars data, give it to the group_by() function and then compute the mean height”. Without the %&gt;%, one would need to write: summarise(group_by(starwars, species), mean(height)) ## # A tibble: 38 x 2 ## species `mean(height)` ## &lt;chr&gt; &lt;dbl&gt; ## 1 Aleena 79.0000 ## 2 Besalisk 198.0000 ## 3 Cerean 198.0000 ## 4 Chagrian 196.0000 ## 5 Clawdite 168.0000 ## 6 Droid NA ## 7 Dug 112.0000 ## 8 Ewok 88.0000 ## 9 Geonosian 183.0000 ## 10 Gungan 208.6667 ## # ... with 28 more rows as you can see, it is much more difficult to read. Imagine now that I want average height by species, but only for males. Again, this is very easy using %&gt;%: starwars %&gt;% filter(gender == &quot;male&quot;) %&gt;% group_by(species) %&gt;% summarise(mean(height)) ## # A tibble: 32 x 2 ## species `mean(height)` ## &lt;chr&gt; &lt;dbl&gt; ## 1 Aleena 79.0000 ## 2 Besalisk 198.0000 ## 3 Cerean 198.0000 ## 4 Chagrian 196.0000 ## 5 Dug 112.0000 ## 6 Ewok 88.0000 ## 7 Geonosian 183.0000 ## 8 Gungan 208.6667 ## 9 Human NA ## 10 Iktotchi 188.0000 ## # ... with 22 more rows Again, the %&gt;% makes the above lines of code very easy to read. Without it, one would write: summarise(group_by(filter(starwars, gender == &quot;male&quot;), species), mean(height)) ## # A tibble: 32 x 2 ## species `mean(height)` ## &lt;chr&gt; &lt;dbl&gt; ## 1 Aleena 79.0000 ## 2 Besalisk 198.0000 ## 3 Cerean 198.0000 ## 4 Chagrian 196.0000 ## 5 Dug 112.0000 ## 6 Ewok 88.0000 ## 7 Geonosian 183.0000 ## 8 Gungan 208.6667 ## 9 Human NA ## 10 Iktotchi 188.0000 ## # ... with 22 more rows I think you agree with me that this is not very readable. Once you’re used to %&gt;%, you won’t go back to not use it. To make things clearer; filter(), group_by() and summarise() are functions that are included in dplyr. %&gt;% is actually a function from magrittr, but this package gets loaded when you load dplyr automatically, so you do not need to worry about it. mean() is a function native to R. Another thing very nice about using dplyr; the result of all these operations are datasets, or tibbles. This means that you can save them in variable, and then work with these as any other datasets. mean_height = starwars %&gt;% group_by(species) %&gt;% summarise(mean(height)) class(mean_height) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; head(mean_height) ## # A tibble: 6 x 2 ## species `mean(height)` ## &lt;chr&gt; &lt;dbl&gt; ## 1 Aleena 79 ## 2 Besalisk 198 ## 3 Cerean 198 ## 4 Chagrian 196 ## 5 Clawdite 168 ## 6 Droid NA You could then write this data to disk using rio::export() for instance. If you need more than the mean of the height, you can keep adding as many functions as needed: summary_table = starwars %&gt;% group_by(species) %&gt;% summarise(ave_height = mean(height), var_height = var(height), n_obs = n()) print(summary_table) ## # A tibble: 38 x 4 ## species ave_height var_height n_obs ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Aleena 79.0000 NA 1 ## 2 Besalisk 198.0000 NA 1 ## 3 Cerean 198.0000 NA 1 ## 4 Chagrian 196.0000 NA 1 ## 5 Clawdite 168.0000 NA 1 ## 6 Droid NA NA 5 ## 7 Dug 112.0000 NA 1 ## 8 Ewok 88.0000 NA 1 ## 9 Geonosian 183.0000 NA 1 ## 10 Gungan 208.6667 201.3333 3 ## # ... with 28 more rows I did several things there; I’ve added more functions, var() to get the variance and n() (which is a function from dplyr, not base R) to get the number of observations. This is quite useful, because we see that for a lot of species we only have one single individual! Let’s focus on the species for which we have more than 1 individual. Since we save all the previous operations (which produce a tibble) in a variable, we can keep going from there: summary_table2 = summary_table %&gt;% filter(n_obs &gt; 1) print(summary_table2) ## # A tibble: 9 x 4 ## species ave_height var_height n_obs ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Droid NA NA 5 ## 2 Gungan 208.6667 201.3333 3 ## 3 Human NA NA 35 ## 4 Kaminoan 221.0000 128.0000 2 ## 5 Mirialan 168.0000 8.0000 2 ## 6 Twi&#39;lek 179.0000 2.0000 2 ## 7 Wookiee 231.0000 18.0000 2 ## 8 Zabrak 173.0000 8.0000 2 ## 9 &lt;NA&gt; NA NA 5 There’s a lot of NAs; this is because by default, mean() and var() return NA if even one single observation is NA (unlike STATA). mean() and var() have a na.rm option that the user can set to TRUE to get the result by ignoring the NAs: starwars %&gt;% group_by(species) %&gt;% summarise(ave_height = mean(height, na.rm = TRUE), var_height = var(height, na.rm = TRUE), n_obs = n()) %&gt;% filter(n_obs &gt; 1) ## # A tibble: 9 x 4 ## species ave_height var_height n_obs ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Droid 140.0000 2704.6667 5 ## 2 Gungan 208.6667 201.3333 3 ## 3 Human 176.6452 157.1699 35 ## 4 Kaminoan 221.0000 128.0000 2 ## 5 Mirialan 168.0000 8.0000 2 ## 6 Twi&#39;lek 179.0000 2.0000 2 ## 7 Wookiee 231.0000 18.0000 2 ## 8 Zabrak 173.0000 8.0000 2 ## 9 &lt;NA&gt; 160.0000 1826.0000 5 In the code above, I have combined the two previous steps to get the result I’m interested in. There’s a line in the final output that says NA for the species. Let’s go back to the raw data and find these lines: starwars %&gt;% filter(is.na(species)) ## # A tibble: 5 x 13 ## name height mass hair_color skin_color eye_color birth_year ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Ric Olié 183 NA brown fair blue NA ## 2 Quarsh Panaka 183 NA black dark brown 62 ## 3 R4-P17 96 NA none silver, red red, blue NA ## 4 Sly Moore 178 48 none pale white NA ## 5 Captain Phasma NA NA unknown unknown unknown NA ## # ... with 6 more variables: gender &lt;chr&gt;, homeworld &lt;chr&gt;, species &lt;chr&gt;, ## # films &lt;list&gt;, vehicles &lt;list&gt;, starships &lt;list&gt; To test for NA, one uses the function is.na() not something like species == &quot;NA&quot; or anything like that.!is.na() does the opposite: starwars %&gt;% filter(!is.na(species)) ## # A tibble: 82 x 13 ## name height mass hair_color skin_color eye_color ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Luke Skywalker 172 77 blond fair blue ## 2 C-3PO 167 75 &lt;NA&gt; gold yellow ## 3 R2-D2 96 32 &lt;NA&gt; white, blue red ## 4 Darth Vader 202 136 none white yellow ## 5 Leia Organa 150 49 brown light brown ## 6 Owen Lars 178 120 brown, grey light blue ## 7 Beru Whitesun lars 165 75 brown light blue ## 8 R5-D4 97 32 &lt;NA&gt; white, red red ## 9 Biggs Darklighter 183 84 black light brown ## 10 Obi-Wan Kenobi 182 77 auburn, white fair blue-gray ## # ... with 72 more rows, and 7 more variables: birth_year &lt;dbl&gt;, ## # gender &lt;chr&gt;, homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;, ## # vehicles &lt;list&gt;, starships &lt;list&gt; The ! function negates a predicate function (a predicate function is a function that returns TRUE or FALSE). We can then rerun our analysis from before: starwars %&gt;% filter(!is.na(species)) %&gt;% group_by(species) %&gt;% summarise(ave_height = mean(height, na.rm = TRUE), var_height = var(height, na.rm = TRUE), n_obs = n()) %&gt;% filter(n_obs &gt; 1) ## # A tibble: 8 x 4 ## species ave_height var_height n_obs ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Droid 140.0000 2704.6667 5 ## 2 Gungan 208.6667 201.3333 3 ## 3 Human 176.6452 157.1699 35 ## 4 Kaminoan 221.0000 128.0000 2 ## 5 Mirialan 168.0000 8.0000 2 ## 6 Twi&#39;lek 179.0000 2.0000 2 ## 7 Wookiee 231.0000 18.0000 2 ## 8 Zabrak 173.0000 8.0000 2 And why not compute the same table, but adding another stratifying variable? starwars %&gt;% filter(!is.na(species)) %&gt;% group_by(species, gender) %&gt;% summarise(ave_height = mean(height, na.rm = TRUE), var_height = var(height, na.rm = TRUE), n_obs = n()) %&gt;% filter(n_obs &gt; 1) ## # A tibble: 8 x 5 ## # Groups: species [6] ## species gender ave_height var_height n_obs ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Droid none 200.0000 NA 2 ## 2 Droid &lt;NA&gt; 120.0000 1657.00000 3 ## 3 Gungan male 208.6667 201.33333 3 ## 4 Human female 160.2500 48.78571 9 ## 5 Human male 182.3478 67.05534 26 ## 6 Mirialan female 168.0000 8.00000 2 ## 7 Wookiee male 231.0000 18.00000 2 ## 8 Zabrak male 173.0000 8.00000 2 dplyr contains a lot of different functions, one of which is mutate(). mutate() allows you to create new columns. For instance, suppose you need a column of the height of the individuals in meters, and not in centimeters: starwars = starwars %&gt;% mutate(height_m = height/100) glimpse(starwars) ## Observations: 87 ## Variables: 14 ## $ name &lt;chr&gt; &quot;Luke Skywalker&quot;, &quot;C-3PO&quot;, &quot;R2-D2&quot;, &quot;Darth Vader&quot;, ... ## $ height &lt;int&gt; 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188... ## $ mass &lt;dbl&gt; 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 8... ## $ hair_color &lt;chr&gt; &quot;blond&quot;, NA, NA, &quot;none&quot;, &quot;brown&quot;, &quot;brown, grey&quot;, &quot;b... ## $ skin_color &lt;chr&gt; &quot;fair&quot;, &quot;gold&quot;, &quot;white, blue&quot;, &quot;white&quot;, &quot;light&quot;, &quot;l... ## $ eye_color &lt;chr&gt; &quot;blue&quot;, &quot;yellow&quot;, &quot;red&quot;, &quot;yellow&quot;, &quot;brown&quot;, &quot;blue&quot;,... ## $ birth_year &lt;dbl&gt; 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0... ## $ gender &lt;chr&gt; &quot;male&quot;, NA, NA, &quot;male&quot;, &quot;female&quot;, &quot;male&quot;, &quot;female&quot;,... ## $ homeworld &lt;chr&gt; &quot;Tatooine&quot;, &quot;Tatooine&quot;, &quot;Naboo&quot;, &quot;Tatooine&quot;, &quot;Alder... ## $ species &lt;chr&gt; &quot;Human&quot;, &quot;Droid&quot;, &quot;Droid&quot;, &quot;Human&quot;, &quot;Human&quot;, &quot;Human... ## $ films &lt;list&gt; [&lt;&quot;Revenge of the Sith&quot;, &quot;Return of the Jedi&quot;, &quot;Th... ## $ vehicles &lt;list&gt; [&lt;&quot;Snowspeeder&quot;, &quot;Imperial Speeder Bike&quot;&gt;, &lt;&gt;, &lt;&gt;,... ## $ starships &lt;list&gt; [&lt;&quot;X-wing&quot;, &quot;Imperial shuttle&quot;&gt;, &lt;&gt;, &lt;&gt;, &quot;TIE Adva... ## $ height_m &lt;dbl&gt; 1.72, 1.67, 0.96, 2.02, 1.50, 1.78, 1.65, 0.97, 1.8... I have used mutate() to compute the column I need and glimpse() is an alternative to print() that I find very useful because it shows all the columns with as many observations that fit on your screen. We can see the column we created at the very bottom. It might be interesting to reorder the columns; this is possible with select() another dplyr function: starwars = starwars %&gt;% select(name, height, height_m, everything()) glimpse(starwars) ## Observations: 87 ## Variables: 14 ## $ name &lt;chr&gt; &quot;Luke Skywalker&quot;, &quot;C-3PO&quot;, &quot;R2-D2&quot;, &quot;Darth Vader&quot;, ... ## $ height &lt;int&gt; 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188... ## $ height_m &lt;dbl&gt; 1.72, 1.67, 0.96, 2.02, 1.50, 1.78, 1.65, 0.97, 1.8... ## $ mass &lt;dbl&gt; 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 8... ## $ hair_color &lt;chr&gt; &quot;blond&quot;, NA, NA, &quot;none&quot;, &quot;brown&quot;, &quot;brown, grey&quot;, &quot;b... ## $ skin_color &lt;chr&gt; &quot;fair&quot;, &quot;gold&quot;, &quot;white, blue&quot;, &quot;white&quot;, &quot;light&quot;, &quot;l... ## $ eye_color &lt;chr&gt; &quot;blue&quot;, &quot;yellow&quot;, &quot;red&quot;, &quot;yellow&quot;, &quot;brown&quot;, &quot;blue&quot;,... ## $ birth_year &lt;dbl&gt; 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0... ## $ gender &lt;chr&gt; &quot;male&quot;, NA, NA, &quot;male&quot;, &quot;female&quot;, &quot;male&quot;, &quot;female&quot;,... ## $ homeworld &lt;chr&gt; &quot;Tatooine&quot;, &quot;Tatooine&quot;, &quot;Naboo&quot;, &quot;Tatooine&quot;, &quot;Alder... ## $ species &lt;chr&gt; &quot;Human&quot;, &quot;Droid&quot;, &quot;Droid&quot;, &quot;Human&quot;, &quot;Human&quot;, &quot;Human... ## $ films &lt;list&gt; [&lt;&quot;Revenge of the Sith&quot;, &quot;Return of the Jedi&quot;, &quot;Th... ## $ vehicles &lt;list&gt; [&lt;&quot;Snowspeeder&quot;, &quot;Imperial Speeder Bike&quot;&gt;, &lt;&gt;, &lt;&gt;,... ## $ starships &lt;list&gt; [&lt;&quot;X-wing&quot;, &quot;Imperial shuttle&quot;&gt;, &lt;&gt;, &lt;&gt;, &quot;TIE Adva... select() allows you to reorder columns by writing the order of the columns you want, and then you can use everything() (another dplyr function) to just tell select() that you want everything else in there. But select() also allows you to only select a subset of columns, if needed: starwars %&gt;% select(name, height, height_m, gender) %&gt;% glimpse() ## Observations: 87 ## Variables: 4 ## $ name &lt;chr&gt; &quot;Luke Skywalker&quot;, &quot;C-3PO&quot;, &quot;R2-D2&quot;, &quot;Darth Vader&quot;, &quot;L... ## $ height &lt;int&gt; 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188, ... ## $ height_m &lt;dbl&gt; 1.72, 1.67, 0.96, 2.02, 1.50, 1.78, 1.65, 0.97, 1.83,... ## $ gender &lt;chr&gt; &quot;male&quot;, NA, NA, &quot;male&quot;, &quot;female&quot;, &quot;male&quot;, &quot;female&quot;, N... The last thing I want to show you are the so-called scoped version of these functions. For example, what if I am only interested in columns that contains text? Is there a way to select them automatically? For this type of tasks, you can use select_if(): starwars %&gt;% select_if(is.character) ## # A tibble: 87 x 7 ## name hair_color skin_color eye_color gender homeworld ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Luke Skywalker blond fair blue male Tatooine ## 2 C-3PO &lt;NA&gt; gold yellow &lt;NA&gt; Tatooine ## 3 R2-D2 &lt;NA&gt; white, blue red &lt;NA&gt; Naboo ## 4 Darth Vader none white yellow male Tatooine ## 5 Leia Organa brown light brown female Alderaan ## 6 Owen Lars brown, grey light blue male Tatooine ## 7 Beru Whitesun lars brown light blue female Tatooine ## 8 R5-D4 &lt;NA&gt; white, red red &lt;NA&gt; Tatooine ## 9 Biggs Darklighter black light brown male Tatooine ## 10 Obi-Wan Kenobi auburn, white fair blue-gray male Stewjon ## # ... with 77 more rows, and 1 more variables: species &lt;chr&gt; select_if() selects every column that is of type character. There is also select_all() and select_at(), each with they’re own use. I will not go into more detail here. If you are interested, I advise you read dplyr’s help and also the section I wrote in my other book which goes into much more detail. 5.1.2 Reshaping data with tidyr Another important package from the tidyverse that goes hand in hand with dplyr is tidyr. tidyr is the package you need when it’s time to reshape data. The basic functions from tidyr, spread() and gather() make it possible to go from long to wide datasets respectively. library(tidyr) survey_data = tribble( ~id, ~variable, ~value, 1, &quot;var1&quot;, 1, 1, &quot;var2&quot;, 0.2, 2, &quot;var1&quot;, 1.4, 2, &quot;var2&quot;, 1.9, 3, &quot;var1&quot;, 0.1, 3, &quot;var2&quot;, 2.8, 4, &quot;var1&quot;, 1.7, 4, &quot;var2&quot;, 1.9 ) head(survey_data) ## # A tibble: 6 x 3 ## id variable value ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 var1 1.0 ## 2 1 var2 0.2 ## 3 2 var1 1.4 ## 4 2 var2 1.9 ## 5 3 var1 0.1 ## 6 3 var2 2.8 This above is a long dataset. We can reshape it to be wide using the spread() function: wide_data = survey_data %&gt;% spread(variable, value) head(wide_data) ## # A tibble: 4 x 3 ## id var1 var2 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1.0 0.2 ## 2 2 1.4 1.9 ## 3 3 0.1 2.8 ## 4 4 1.7 1.9 This means that we spread the column called “variable”, which will produce one column per category of “variable”. Then we fill in the rows with the data contained in the column “value”. To go from a wide dataset to a long one, we use gather(): long_data = wide_data %&gt;% gather(variable, value, var1, var2) print(long_data) ## # A tibble: 8 x 3 ## id variable value ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 var1 1.0 ## 2 2 var1 1.4 ## 3 3 var1 0.1 ## 4 4 var1 1.7 ## 5 1 var2 0.2 ## 6 2 var2 1.9 ## 7 3 var2 2.8 ## 8 4 var2 1.9 long_data and survey_data are the same datasets, but in a different order. In the wide_data tibble, we had 3 columns: id, var1 and var2. We want to stack ‘var1’ and ‘var2’ in a new column, that we chose to call “variable”. This is the “key”. For the value, we are using the values contained in var1 and var2. Sometimes using spread() or gather() requires some trial and error. I advise you play around with the examples above to really grasp how these powerful functions work. The last function from tidyr that we are going to discuss is nest(), but we will keep it for later, in the section about so-called list-columns. 5.2 Working with a list of datasets 5.2.1 Getting to know map() Let’s read the list of datasets from the previous chapter: paths = Sys.glob(&quot;datasets/unemployment/*.csv&quot;) all_datasets = import_list(paths) str(all_datasets) ## List of 4 ## $ :&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ Commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ Total employed population : int [1:118] 223407 17802 1703 844 1431 4094 2146 971 1218 3002 ... ## ..$ of which: Wage-earners : int [1:118] 203535 15993 1535 750 1315 3800 1874 858 1029 2664 ... ## ..$ of which: Non-wage-earners: int [1:118] 19872 1809 168 94 116 294 272 113 189 338 ... ## ..$ Unemployed : int [1:118] 19287 1071 114 25 74 261 98 45 66 207 ... ## ..$ Active population : int [1:118] 242694 18873 1817 869 1505 4355 2244 1016 1284 3209 ... ## ..$ Unemployment rate (in %) : num [1:118] 7.95 5.67 6.27 2.88 4.92 ... ## ..$ Year : int [1:118] 2013 2013 2013 2013 2013 2013 2013 2013 2013 2013 ... ## $ :&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ Commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ Total employed population : int [1:118] 228423 18166 1767 845 1505 4129 2172 1007 1268 3124 ... ## ..$ of which: Wage-earners : int [1:118] 208238 16366 1606 757 1390 3840 1897 887 1082 2782 ... ## ..$ of which: Non-wage-earners: int [1:118] 20185 1800 161 88 115 289 275 120 186 342 ... ## ..$ Unemployed : int [1:118] 19362 1066 122 19 66 287 91 38 61 202 ... ## ..$ Active population : int [1:118] 247785 19232 1889 864 1571 4416 2263 1045 1329 3326 ... ## ..$ Unemployment rate (in %) : num [1:118] 7.81 5.54 6.46 2.2 4.2 ... ## ..$ Year : int [1:118] 2014 2014 2014 2014 2014 2014 2014 2014 2014 2014 ... ## $ :&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ Commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ Total employed population : int [1:118] 233130 18310 1780 870 1470 4130 2170 1050 1300 3140 ... ## ..$ of which: Wage-earners : int [1:118] 212530 16430 1620 780 1350 3820 1910 920 1100 2770 ... ## ..$ of which: Non-wage-earners: int [1:118] 20600 1880 160 90 120 310 260 130 200 370 ... ## ..$ Unemployed : int [1:118] 18806 988 106 29 73 260 80 41 72 169 ... ## ..$ Active population : int [1:118] 251936 19298 1886 899 1543 4390 2250 1091 1372 3309 ... ## ..$ Unemployment rate (in %) : num [1:118] 7.46 5.12 5.62 3.23 4.73 ... ## ..$ Year : int [1:118] 2015 2015 2015 2015 2015 2015 2015 2015 2015 2015 ... ## $ :&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ Commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ Total employed population : int [1:118] 236100 18380 1790 870 1470 4160 2160 1030 1330 3150 ... ## ..$ of which: Wage-earners : int [1:118] 215430 16500 1640 780 1350 3840 1900 900 1130 2780 ... ## ..$ of which: Non-wage-earners: int [1:118] 20670 1880 150 90 120 320 260 130 200 370 ... ## ..$ Unemployed : int [1:118] 18185 975 91 27 66 246 76 35 70 206 ... ## ..$ Active population : int [1:118] 254285 19355 1881 897 1536 4406 2236 1065 1400 3356 ... ## ..$ Unemployment rate (in %) : num [1:118] 7.15 5.04 4.84 3.01 4.3 ... ## ..$ Year : int [1:118] 2016 2016 2016 2016 2016 2016 2016 2016 2016 2016 ... For working with lists, another package from the tidyverse is very useful, and that would be purrr. purrr has functions to work with lists, and we are going to focus on two of them, map() and reduce(). map()… maps a function to each element of a list. reduce() is a bit more complicated so we’ll leave that for later. The first thing we are going to do is use a function to clean the names of the datasets. These names are not very easy to work with; there are spaces, and it would be better if the names of the columns would be all lowercase. For this we are going to use the function clean_names() from the janitor package. For a single dataset, I would write this: library(janitor) one_dataset = one_dataset %&gt;% clean_names() and I would get a dataset with column names in lowercase and spaces replaced by _ (and other corrections). How can I apply, or map, this function to each dataset in the list? To do this I need to use purrr::map(): library(purrr) all_datasets = all_datasets %&gt;% map(clean_names) all_datasets %&gt;% glimpse() ## List of 4 ## $ :&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ total_employed_population : int [1:118] 223407 17802 1703 844 1431 4094 2146 971 1218 3002 ... ## ..$ of_which_wage_earners : int [1:118] 203535 15993 1535 750 1315 3800 1874 858 1029 2664 ... ## ..$ of_which_non_wage_earners : int [1:118] 19872 1809 168 94 116 294 272 113 189 338 ... ## ..$ unemployed : int [1:118] 19287 1071 114 25 74 261 98 45 66 207 ... ## ..$ active_population : int [1:118] 242694 18873 1817 869 1505 4355 2244 1016 1284 3209 ... ## ..$ unemployment_rate_in_percent: num [1:118] 7.95 5.67 6.27 2.88 4.92 ... ## ..$ year : int [1:118] 2013 2013 2013 2013 2013 2013 2013 2013 2013 2013 ... ## $ :&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ total_employed_population : int [1:118] 228423 18166 1767 845 1505 4129 2172 1007 1268 3124 ... ## ..$ of_which_wage_earners : int [1:118] 208238 16366 1606 757 1390 3840 1897 887 1082 2782 ... ## ..$ of_which_non_wage_earners : int [1:118] 20185 1800 161 88 115 289 275 120 186 342 ... ## ..$ unemployed : int [1:118] 19362 1066 122 19 66 287 91 38 61 202 ... ## ..$ active_population : int [1:118] 247785 19232 1889 864 1571 4416 2263 1045 1329 3326 ... ## ..$ unemployment_rate_in_percent: num [1:118] 7.81 5.54 6.46 2.2 4.2 ... ## ..$ year : int [1:118] 2014 2014 2014 2014 2014 2014 2014 2014 2014 2014 ... ## $ :&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ total_employed_population : int [1:118] 233130 18310 1780 870 1470 4130 2170 1050 1300 3140 ... ## ..$ of_which_wage_earners : int [1:118] 212530 16430 1620 780 1350 3820 1910 920 1100 2770 ... ## ..$ of_which_non_wage_earners : int [1:118] 20600 1880 160 90 120 310 260 130 200 370 ... ## ..$ unemployed : int [1:118] 18806 988 106 29 73 260 80 41 72 169 ... ## ..$ active_population : int [1:118] 251936 19298 1886 899 1543 4390 2250 1091 1372 3309 ... ## ..$ unemployment_rate_in_percent: num [1:118] 7.46 5.12 5.62 3.23 4.73 ... ## ..$ year : int [1:118] 2015 2015 2015 2015 2015 2015 2015 2015 2015 2015 ... ## $ :&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ total_employed_population : int [1:118] 236100 18380 1790 870 1470 4160 2160 1030 1330 3150 ... ## ..$ of_which_wage_earners : int [1:118] 215430 16500 1640 780 1350 3840 1900 900 1130 2780 ... ## ..$ of_which_non_wage_earners : int [1:118] 20670 1880 150 90 120 320 260 130 200 370 ... ## ..$ unemployed : int [1:118] 18185 975 91 27 66 246 76 35 70 206 ... ## ..$ active_population : int [1:118] 254285 19355 1881 897 1536 4406 2236 1065 1400 3356 ... ## ..$ unemployment_rate_in_percent: num [1:118] 7.15 5.04 4.84 3.01 4.3 ... ## ..$ year : int [1:118] 2016 2016 2016 2016 2016 2016 2016 2016 2016 2016 ... So now, what if I want to know, for each dataset, which communes have an unemployment rate that is less than, say, 3%? For a single dataset I would do something like this: one_dataset %&gt;% filter(unemployment_rate_in_percent &lt; 3) But for a list of datasets, map() is needed (and as you will see, that is not all that is needed): all_datasets %&gt;% map(~filter(., unemployment_rate_in_percent &lt; 3)) ## [[1]] ## commune total_employed_population of_which_wage_earners ## 1 Garnich 844 750 ## 2 Leudelange 1064 937 ## 3 Bech 526 463 ## of_which_non_wage_earners unemployed active_population ## 1 94 25 869 ## 2 127 32 1096 ## 3 63 16 542 ## unemployment_rate_in_percent year ## 1 2.876870 2013 ## 2 2.919708 2013 ## 3 2.952030 2013 ## ## [[2]] ## commune total_employed_population of_which_wage_earners ## 1 Garnich 845 757 ## 2 Leudelange 1102 965 ## 3 Bech 543 476 ## 4 Flaxweiler 879 789 ## of_which_non_wage_earners unemployed active_population ## 1 88 19 864 ## 2 137 34 1136 ## 3 67 15 558 ## 4 90 27 906 ## unemployment_rate_in_percent year ## 1 2.199074 2014 ## 2 2.992958 2014 ## 3 2.688172 2014 ## 4 2.980132 2014 ## ## [[3]] ## commune total_employed_population of_which_wage_earners ## 1 Bech 520 450 ## 2 Bous 750 680 ## of_which_non_wage_earners unemployed active_population ## 1 70 14 534 ## 2 70 22 772 ## unemployment_rate_in_percent year ## 1 2.621723 2015 ## 2 2.849741 2015 ## ## [[4]] ## commune total_employed_population of_which_wage_earners ## 1 Reckange-sur-Mess 980 850 ## 2 Bech 520 450 ## 3 Betzdorf 1500 1350 ## 4 Flaxweiler 910 820 ## of_which_non_wage_earners unemployed active_population ## 1 130 30 1010 ## 2 70 11 531 ## 3 150 45 1545 ## 4 90 24 934 ## unemployment_rate_in_percent year ## 1 2.970297 2016 ## 2 2.071563 2016 ## 3 2.912621 2016 ## 4 2.569593 2016 I know what you’re thinking… what the hell?. Let me explain: map() needs a function to map to each element of the list. all_datasets is the list to which I want to map the function. But what function? filter() is the function I need, so why doesn’t: all_datasets %&gt;% map(filter(unemployment_rate_in_percent &lt; 3)) work? This is a bit complicated, and has to do with what is called environments. If you try to run the code above, you will get this error message: Error in filter(unemployment_rate_in_percent &lt; 3) : object &#39;unemployment_rate_in_percent&#39; not found I won’t go into details, but by writing ~filter(., unemployment_rate_in_percent &lt; 3), which is a formula (~ is the symbol to define formulas, more on this in the later chapters), map() converts it to a function that it can use. If you want to know more about this, you can read it in Advanced R by Hadley Wickham, but it is an advanced topic. 5.2.2 Getting to know reduce() Using map() we now know how to apply a function to each dataset of a list. But maybe it would be easier to merge all the datasets first, and then manipulate them? Before that though, I am going to teach you how to use purrr::reduce(), another very powerful function that works on lists. This is a function that you can find in other programming languages, but sometimes it is called fold. I think that the following example illustrates the power of reduce() well: numbers = seq(1, 5) # Create a vector with the numbers 1 to 5 reduce(numbers, `+`, .init = 0) ## [1] 15 reduce() takes a function as an argument, here the function +2 and then does the following computation: 0 + numbers[1] + numbers[2] + numbers[3]... It applies the user supplied function successively but has to start with something, so we give it the argument init also. This argument is actually optional, but I show it here because in some cases it might be useful to start the computations at another value than 0.reduce() generalizes functions that only take two arguments. If you were to write a function that returns the minimum between two numbers: my_min = function(a, b){ if(a &lt; b){ return(a) } else { return(b) } } You could use reduce() to get the minimum of a list of numbers: numbers2 = c(3, 1, -8, 9) reduce(numbers2, my_min) ## [1] -8 As long as you provide a function and a list of elements to reduce(), you will get a single output. So how could reduce() help us with merging all the datasets that are in the list? dplyr comes with a lot of function to merge two datasets. Remember that I said before that reduce() allows you to generalize a function of two arguments? Let’s try it with our list of datasets: unemp_lux = reduce(all_datasets, full_join) ## Joining, by = c(&quot;commune&quot;, &quot;total_employed_population&quot;, &quot;of_which_wage_earners&quot;, &quot;of_which_non_wage_earners&quot;, &quot;unemployed&quot;, &quot;active_population&quot;, &quot;unemployment_rate_in_percent&quot;, &quot;year&quot;) ## Joining, by = c(&quot;commune&quot;, &quot;total_employed_population&quot;, &quot;of_which_wage_earners&quot;, &quot;of_which_non_wage_earners&quot;, &quot;unemployed&quot;, &quot;active_population&quot;, &quot;unemployment_rate_in_percent&quot;, &quot;year&quot;) ## Joining, by = c(&quot;commune&quot;, &quot;total_employed_population&quot;, &quot;of_which_wage_earners&quot;, &quot;of_which_non_wage_earners&quot;, &quot;unemployed&quot;, &quot;active_population&quot;, &quot;unemployment_rate_in_percent&quot;, &quot;year&quot;) glimpse(unemp_lux) ## Observations: 472 ## Variables: 8 ## $ commune &lt;chr&gt; &quot;Grand-Duche de Luxembourg&quot;, &quot;Can... ## $ total_employed_population &lt;int&gt; 223407, 17802, 1703, 844, 1431, 4... ## $ of_which_wage_earners &lt;int&gt; 203535, 15993, 1535, 750, 1315, 3... ## $ of_which_non_wage_earners &lt;int&gt; 19872, 1809, 168, 94, 116, 294, 2... ## $ unemployed &lt;int&gt; 19287, 1071, 114, 25, 74, 261, 98... ## $ active_population &lt;int&gt; 242694, 18873, 1817, 869, 1505, 4... ## $ unemployment_rate_in_percent &lt;dbl&gt; 7.947044, 5.674773, 6.274078, 2.8... ## $ year &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 201... full_join() is one of the dplyr function that merges data. There are others that might be useful depending on the kind of join operation you need. Let’s write this data to disk as we’re going to keep using it for the next chapters: export(unemp_lux, &quot;datasets/unemp_lux.csv&quot;) 5.3 List-columns To learn about list-columns, let’s first focus on a single character of the starwars dataset: data(starwars) starwars %&gt;% filter(name == &quot;Luke Skywalker&quot;) %&gt;% glimpse() ## Observations: 1 ## Variables: 13 ## $ name &lt;chr&gt; &quot;Luke Skywalker&quot; ## $ height &lt;int&gt; 172 ## $ mass &lt;dbl&gt; 77 ## $ hair_color &lt;chr&gt; &quot;blond&quot; ## $ skin_color &lt;chr&gt; &quot;fair&quot; ## $ eye_color &lt;chr&gt; &quot;blue&quot; ## $ birth_year &lt;dbl&gt; 19 ## $ gender &lt;chr&gt; &quot;male&quot; ## $ homeworld &lt;chr&gt; &quot;Tatooine&quot; ## $ species &lt;chr&gt; &quot;Human&quot; ## $ films &lt;list&gt; [&lt;&quot;Revenge of the Sith&quot;, &quot;Return of the Jedi&quot;, &quot;Th... ## $ vehicles &lt;list&gt; [&lt;&quot;Snowspeeder&quot;, &quot;Imperial Speeder Bike&quot;&gt;] ## $ starships &lt;list&gt; [&lt;&quot;X-wing&quot;, &quot;Imperial shuttle&quot;&gt;] We see that the columns films, vehicles and starships are all lists, and in the case of films, it lists all the films where Luke Skywalker has appeared. What if you want to take a closer look at this list? starwars %&gt;% filter(name == &quot;Luke Skywalker&quot;) %&gt;% pull(films) ## [[1]] ## [1] &quot;Revenge of the Sith&quot; &quot;Return of the Jedi&quot; ## [3] &quot;The Empire Strikes Back&quot; &quot;A New Hope&quot; ## [5] &quot;The Force Awakens&quot; pull() is a dplyr function that extract (pulls) the column you’re interested in. It is quite useful when you want to inspect a column. Suppose we want to create a categorical variable which counts the number of movies in which the characters have appeared. For this we need to compute the length of the list, or count the number of elements this list has. Let’s try with length() a base R function: starwars %&gt;% filter(name == &quot;Luke Skywalker&quot;) %&gt;% pull(films) %&gt;% length() ## [1] 1 This might be surprising at first, because we know that Luke Skywalker has appeared in more than 1 movie… the problem here is that for each individual, films is a list, whose single element is a vector of characters. This means that length(films) computes the length of the list, which is one, and not the length of the vector contained in the list! How can we get the length of the vector of characters contained in the list and for each character? For this we need to use dplyr::rowwise() and remove the filter() function and use mutate() to add this column to the dataset: starwars = starwars %&gt;% rowwise() %&gt;% mutate(n_films = length(films)) dplyr::rowwise() is useful when working with list-columns: columns that have lists as elements. Let’s take a look at the characters and the number of films they have appeared in: starwars %&gt;% select(name, n_films) ## Source: local data frame [87 x 2] ## Groups: &lt;by row&gt; ## ## # A tibble: 87 x 2 ## name n_films ## &lt;chr&gt; &lt;int&gt; ## 1 Luke Skywalker 5 ## 2 C-3PO 6 ## 3 R2-D2 7 ## 4 Darth Vader 4 ## 5 Leia Organa 5 ## 6 Owen Lars 3 ## 7 Beru Whitesun lars 3 ## 8 R5-D4 1 ## 9 Biggs Darklighter 1 ## 10 Obi-Wan Kenobi 6 ## # ... with 77 more rows Now we can create a factor variable that groups characters by asking whether they appeared only in 1 movie, or more: starwars = starwars %&gt;% mutate(more_1 = case_when(n_films == 1 ~ &quot;Exactly one movie&quot;, n_films != 1 ~ &quot;More than 1 movie&quot;)) It is also possible to create list-columns with tidyr::nest(): print(survey_data) ## # A tibble: 8 x 3 ## id variable value ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 var1 1.0 ## 2 1 var2 0.2 ## 3 2 var1 1.4 ## 4 2 var2 1.9 ## 5 3 var1 0.1 ## 6 3 var2 2.8 ## 7 4 var1 1.7 ## 8 4 var2 1.9 nested_data = survey_data %&gt;% nest(variable, value) print(nested_data) ## # A tibble: 4 x 2 ## id data ## &lt;dbl&gt; &lt;list&gt; ## 1 1 &lt;tibble [2 x 2]&gt; ## 2 2 &lt;tibble [2 x 2]&gt; ## 3 3 &lt;tibble [2 x 2]&gt; ## 4 4 &lt;tibble [2 x 2]&gt; This creates a new tibble, with columns id and data. data is a list-column that contains tibbles; each tibble is the variable and value for each individual: nested_data %&gt;% filter(id == &quot;1&quot;) %&gt;% pull(data) ## [[1]] ## # A tibble: 2 x 2 ## variable value ## &lt;chr&gt; &lt;dbl&gt; ## 1 var1 1.0 ## 2 var2 0.2 As you can see, for individual 1, the column data contains a 2x2 tibble with columns variable and value. You might be wondering why this is useful, because this seems to introduce an unnecessary layer of complexity. The usefulness of list-columns will become apparent in the next chapters, where we are going to learn how to repeat actions over, say, individuals. This is simply the + operator you’re used to. Try this out: `+`(1, 5) and you’ll see + is a function like any other. You just have to write backticks around the plus symbol to make it work.↩ "],
["graphs.html", "Chapter 6 Graphs 6.1 Resources 6.2 Examples 6.3 Customization 6.4 Many plots", " Chapter 6 Graphs By default, it is possible to make a lot of graphs with R without the need of any external packages. However, in this chapter, we are going to learn how to make graphs using ggplot2 which is a very powerful package that produces amazing graphs. There is an entry cost to ggplot2 as it works in a very different way than what you would expect, especially if you know how to make plots with the basic R functions already. But the resulting graphs are well worth the effort and once you’ll know more about ggplot2 you’ll see that in a lot of situations it is actually faster and easier. Even if you are not interested in drawing plots, I advise you continue reading, as we will dig deeper into functional programming territory and learn how to graph an arbitrary large amount of plots with a few lines of code. 6.1 Resources Before showing some examples and the general functionality of ggplot2, I list here some online resources that I keep coming back to: Data Visualization for Social Science R Graphics Cookbook R graph gallery Tufte in R ggplot2 extensions ggthemes Vignette ggplot2 cheatsheet I have a cookbook approach to using ggplot2; I try to find an example online that looks similar to what I have in mind, copy and paste the code and then adapt it to my case. The above resources are the ones I consult the most in these situations (I also go back to past code I’ve written, of course). Don’t hesitate to skim these resources for inspiration and to learn more about some extensions to ggplot2. In the next subsections I am going to show you how to draw the most common plots, as well as show you how to customize your plots with ggthemes. 6.2 Examples 6.2.1 Barplots To follow the examples below, load the following libraries: library(ggplot2) library(ggthemes) ggplot2 is an implementation of the Grammar of Graphics by Wilkinson (2006), but you don’t need to read the books to start using it. If we go back to the Star Wars data (contained in dplyr), and wish to draw a barplot of the gender, the following lines are enough: ggplot(starwars, aes(gender)) + geom_bar() The first argument of the function is the data (called starwars in this example), and then the function aes(). This function is where you list the variables you want to map, and to quote the help file of aes(), describes how the variables are mapped to visual properties (aesthetics) of geoms. You can get different kind of plots by using different geom_ functions. You can also change the coordinate system in your barplot: ggplot(starwars, aes(gender)) + geom_bar() + coord_flip() 6.2.2 Density geom_density() is the geom that allows you to get density plots: ggplot(starwars, aes(height)) + geom_density() ## Warning: Removed 6 rows containing non-finite values (stat_density). Let’s go into more detail now; what if you would like to plot the densities for females and males only (removing the droids from the data first)? This can be done by first filtering the data using dplyr and then separating the dataset by gender: starwars %&gt;% filter(gender %in% c(&quot;female&quot;, &quot;male&quot;)) The above lines do the filtering; only keep gender if gender is in the vector &quot;female&quot;, &quot;male&quot;. This is much easier than having to write gender == &quot;female&quot; | gender == &quot;male&quot;. Then, we pipe this dataset to ggplot: starwars %&gt;% filter(gender %in% c(&quot;female&quot;, &quot;male&quot;)) %&gt;% ggplot(aes(height, fill = gender)) + geom_density() ## Warning: Removed 5 rows containing non-finite values (stat_density). Let’s take a closer look to the aes() function: I’ve added fill = gender. This means that the there will be one density plot for each gender in the data, and each will be coloured accordingly. This is where ggplot2 might be confusing; there is no need to write explicitly (even if it is possible) that you want the female density to be red and the male density to be blue. You just map the variable gender to this particular aesthetic. You conclude the plot by adding geom_density() which is this case is the plot you want. We will see later how to change the colours of your plot. 6.2.3 Line plots For the line plots, we are going to use official unemployment data (the same as in the previous chapter, but with all the available years). Get it from here (downloaded from: http://www.statistiques.public.lu/stat/TableViewer/tableView.aspx?ReportId=12950&amp;IF_Language=eng&amp;MainTheme=2&amp;FldrName=3&amp;RFPath=91). Let’s plot the unemployment for the canton of Luxembourg only: unemp_lux_data = import(&quot;datasets/unemployment/all/unemployment_lux_all.csv&quot;) unemp_lux_data %&gt;% filter(division == &quot;Luxembourg&quot;) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = 1)) + geom_line() Because line plots are 2D, you need to specify the y and x axes. There is also another option you need to add, group = 1. This is to tell aes() that the dots have to be connected with a single line. What if you want to plot more than one commune? unemp_lux_data %&gt;% filter(division == &quot;Luxembourg&quot; | division == &quot;Esch-sur-Alzette&quot;) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + geom_line() This time, I’ve specified group = division which means that there has to be one line per as many communes as in the variable division. I do the same for colours. I think the next example illustrates how ggplot2 is actually brilliant; if you need to add a third commune, there is no need to specify anything else; no need to add anything to the legend, no need to specify a third colour etc: unemp_lux_data %&gt;% filter(division %in% c(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;)) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + geom_line() 6.2.4 Facets In some case you have a factor variable that separates the data you wish to plot into different categories. If you want to have a plot per category you can use the facet_grid() function. Careful though, this function does not take a variable as an argument, but a formula, hence the ~ symbol in the code below: starwars %&gt;% mutate(human = case_when(species == &quot;Human&quot; ~ &quot;Human&quot;, species != &quot;Human&quot; ~ &quot;Not Human&quot;)) %&gt;% filter(gender %in% c(&quot;female&quot;, &quot;male&quot;), !is.na(human)) %&gt;% ggplot(aes(height, fill = gender)) + facet_grid(. ~ human) + #&lt;--- this is a formula geom_density() ## Warning: Removed 4 rows containing non-finite values (stat_density). By changing the formula, you change how the facetting is done: starwars %&gt;% mutate(human = case_when(species == &quot;Human&quot; ~ &quot;Human&quot;, species != &quot;Human&quot; ~ &quot;Not Human&quot;)) %&gt;% filter(gender %in% c(&quot;female&quot;, &quot;male&quot;), !is.na(human)) %&gt;% ggplot(aes(height, fill = gender)) + facet_grid(human ~ .) + geom_density() ## Warning: Removed 4 rows containing non-finite values (stat_density). Recall the categorical variable more_1 that we computed in the previous chapter? Let’s use it as a faceting variable: starwars %&gt;% rowwise() %&gt;% mutate(n_films = length(films)) %&gt;% mutate(more_1 = case_when(n_films == 1 ~ &quot;Exactly one movie&quot;, n_films != 1 ~ &quot;More than 1 movie&quot;)) %&gt;% mutate(human = case_when(species == &quot;Human&quot; ~ &quot;Human&quot;, species != &quot;Human&quot; ~ &quot;Not Human&quot;)) %&gt;% filter(gender %in% c(&quot;female&quot;, &quot;male&quot;), !is.na(human)) %&gt;% ggplot(aes(height, fill = gender)) + facet_grid(human ~ more_1) + geom_density() ## Warning: Removed 4 rows containing non-finite values (stat_density). 6.2.5 Pie Charts I am not a huge fan of pie charts, but sometimes this is what you have to do. So let’s see how you can create pie charts. First, let’s create a mock dataset with the function tibble::tribble() which allows you to create a dataset line by line: test_data &lt;- tribble( ~id, ~var1, ~var2, ~var3, ~var4, ~var5, &quot;a&quot;, 26.5, 38, 30, 32, 34, &quot;b&quot;, 30, 30, 28, 32, 30, &quot;c&quot;, 34, 32, 30, 28, 26.5 ) This data is not in the right format though, which is wide. We need to have it in the long format for it to work with ggplot2. For this, let’s use tidyr::gather() as seen in the previous chapter: test_data_long = test_data %&gt;% gather(variable, value, starts_with(&quot;var&quot;)) Now, let’s plot this data, first by creating 3 bar plots: ggplot(test_data_long) + facet_wrap(~id) + geom_bar(aes(variable, value, fill = variable), stat = &quot;identity&quot;) In the code above, I introduce a new option, called stat = &quot;identity&quot;. By default, geom_bar() counts the number of observations of each category that is plotted, which is a statistical transformation. By adding stat = &quot;identity&quot;, I force the statistical transformation to be the identity function, and thus plot the data as is. To create the pie chart, first we need to compute the share of each id to var1, var2, etc… To do this, we first group by id, then compute the total. Then we use a new function ungroup(). After using ungroup() all the computations are done on the whole dataset instead of by group, which is what we need to compute the share: test_data_long = test_data_long %&gt;% group_by(id) %&gt;% mutate(total = sum(value)) %&gt;% ungroup() %&gt;% mutate(share = value/total) Let’s take a look to see if this is what we wanted: print(test_data_long) ## # A tibble: 15 x 5 ## id variable value total share ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a var1 26.5 160.5 0.1651090 ## 2 b var1 30.0 150.0 0.2000000 ## 3 c var1 34.0 150.5 0.2259136 ## 4 a var2 38.0 160.5 0.2367601 ## 5 b var2 30.0 150.0 0.2000000 ## 6 c var2 32.0 150.5 0.2126246 ## 7 a var3 30.0 160.5 0.1869159 ## 8 b var3 28.0 150.0 0.1866667 ## 9 c var3 30.0 150.5 0.1993355 ## 10 a var4 32.0 160.5 0.1993769 ## 11 b var4 32.0 150.0 0.2133333 ## 12 c var4 28.0 150.5 0.1860465 ## 13 a var5 34.0 160.5 0.2118380 ## 14 b var5 30.0 150.0 0.2000000 ## 15 c var5 26.5 150.5 0.1760797 If you didn’t understand what ungroup() did, rerun the last few lines with it and inspect the output. To plot the pie chart, we create a barplot again, but specify polar coordinates: ggplot(test_data_long) + facet_wrap(~id) + geom_bar(aes(y = share, x = &quot;&quot;, fill = variable), stat = &quot;identity&quot;) + theme() + coord_polar(&quot;y&quot;, start = 0) As you can see, this typical pie chart is not very easy to read; compared to the barplots above it is not easy to distinguish a from b from c. It is possible to amend the pie chart a bit to make it clearer, by specifying variable as the x: ggplot(test_data_long) + facet_wrap(~id) + geom_bar(aes(y = share, x = variable, fill = variable), stat = &quot;identity&quot;) + theme() + coord_polar(&quot;x&quot;, start = 0) But as a general rule, avoid pie charts if possible. Barplots show the same information, much, much clearer. 6.2.6 Adding text to plots Sometimes you might want to add some text to your plots. This is possible with geom_text(): ggplot(test_data_long) + facet_wrap(~id) + geom_bar(aes(variable, value, fill = variable), stat = &quot;identity&quot;) + geom_text(aes(variable, value + 1.5, label = value)) You can put anything after label =but in general what you’d want are the values, so that’s what I put there. But you can also refine it, imagine the values are actualy, say €: ggplot(test_data_long) + facet_wrap(~id) + geom_bar(aes(variable, value, fill = variable), stat = &quot;identity&quot;) + geom_text(aes(variable, value + 1.5, label = paste(value, &quot;€&quot;))) 6.3 Customization Every plot you’ve seen until now was made with the default look of ggplot2. If you want to change the look, you can apply a theme, and a colour scheme. Let’s take a look at themes first by using the ones found in the package ggthemes. But first, let’s learn how to change the names of the axes and how to title a plot. 6.3.1 Titles, axes names and more To change the title of the plot, and of the axes, you need to pass the names to the labs() function: unemp_lux_data %&gt;% filter(division %in% c(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;)) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + labs(title = &quot;Unemployment in Luxembourg, Esch/Alzette and Wiltz&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;) + geom_line() What if you want to make the lines thicker? unemp_lux_data %&gt;% filter(division %in% c(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;)) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + labs(title = &quot;Unemployment in Luxembourg, Esch/Alzette and Wiltz&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;) + geom_line(size = 2) 6.3.2 Themes Let’s go back to the unemployment line plots. For now, let’s keep the base ggplot2 theme, but modify it a bit. For example, the legend placement is actually a feature of the theme. This means that if you want to change where the legend is placed you need to modify this feature from the theme. This is done with the function theme(): unemp_lux_data %&gt;% filter(division %in% c(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;)) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + theme(legend.position = &quot;bottom&quot;) + labs(title = &quot;Unemployment in Luxembourg, Esch/Alzette and Wiltz&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;)+ geom_line() What I also like to do is remove the title of the legend, because it is often superfluous: unemp_lux_data %&gt;% filter(division %in% c(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;)) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + theme(legend.position = &quot;bottom&quot;, legend.title = element_blank()) + labs(title = &quot;Unemployment in Luxembourg, Esch/Alzette and Wiltz&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;)+ geom_line() The legend title has to be an element_text object.element_text objects are used with theme to specify how text should be displayed. element_blank() draws nothing and assigns no space (not even blank space). You could modify every feature of the theme like that, but there are built-in themes that you can use: unemp_lux_data %&gt;% filter(division %in% c(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;)) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + theme_minimal() + theme(legend.position = &quot;bottom&quot;, legend.title = element_blank()) + labs(title = &quot;Unemployment in Luxembourg, Esch/Alzette and Wiltz&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;) + geom_line() For example in the code above, I have used theme_minimal() which I like quite a lot. You can also use themes from the ggthemes package, which even contains a STATA theme, if you like it: unemp_lux_data %&gt;% filter(division %in% c(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;)) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + theme_stata() + labs(title = &quot;Unemployment in Luxembourg, Esch/Alzette and Wiltz&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;) + geom_line() As you can see, theme_stata() has the legend on the bottom by default, because this is how the legend position is defined within the theme. However the legend title is still there. Let’s remove it: unemp_lux_data %&gt;% filter(division %in% c(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;)) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + theme_stata() + theme(legend.title = element_blank()) + labs(title = &quot;Unemployment in Luxembourg, Esch/Alzette and Wiltz&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;) + geom_line() ggthemes even features an Excel 2003 theme (don’t use it though): unemp_lux_data %&gt;% filter(division %in% c(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;)) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + theme_excel() + labs(title = &quot;Unemployment in Luxembourg, Esch/Alzette and Wiltz&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;) + geom_line() 6.3.3 Colour schemes from ggthemes You can also change colour schemes, by specifying either scale_colour_* or scale_fill_* functions. scale_colour_* functions are used for continuous variables, while scale_fill_* functions for discrete variables (so for barplots for example). A colour scheme I like is the Highcharts colour scheme. unemp_lux_data %&gt;% filter(division %in% c(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;)) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + theme_minimal() + scale_colour_hc() + theme(legend.position = &quot;bottom&quot;, legend.title = element_blank()) + labs(title = &quot;Unemployment in Luxembourg, Esch/Alzette and Wiltz&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;) + geom_line() An example with a barplot: ggplot(test_data_long) + facet_wrap(~id) + geom_bar(aes(variable, value, fill = variable), stat = &quot;identity&quot;) + geom_text(aes(variable, value + 1.5, label = value)) + theme_minimal() + scale_fill_hc() 6.3.4 Using your own colours To use your own colours you can use scale_colour_manual() and scale_fill_manual() and specify the html codes of the colours you want to use. unemp_lux_data %&gt;% filter(division %in% c(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;)) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + theme_minimal() + scale_colour_manual(values = c(&quot;#FF336C&quot;, &quot;#334BFF&quot;, &quot;#2CAE00&quot;)) + theme(legend.position = &quot;bottom&quot;, legend.title = element_blank()) + labs(title = &quot;Unemployment in Luxembourg, Esch/Alzette and Wiltz&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;) + geom_line() To get html codes of colours you can use this online tool. There is also a very nice package, called colourpicker that allows you to pick colours from with RStudio. Also, you do not even need to load it to use it, since it comes with an Addin: knitr::include_graphics(&quot;pics/rstudio_colourpicker.gif&quot;) For a barplot you would do the same: ggplot(test_data_long) + facet_wrap(~id) + geom_bar(aes(variable, value, fill = variable), stat = &quot;identity&quot;) + geom_text(aes(variable, value + 1.5, label = value)) + theme_minimal() + theme(legend.position = &quot;bottom&quot;, legend.title = element_blank()) + scale_fill_manual(values = c(&quot;#FF336C&quot;, &quot;#334BFF&quot;, &quot;#2CAE00&quot;, &quot;#B3C9C6&quot;, &quot;#765234&quot;)) 6.3.5 Saving plots on disk There are two ways to save plots on disk; one through the Plots in RStudio and another using the ggsave() function. Using RStudio, navigate to the Plots pane and click on Export. You can then choose where to save the plot and other various options: knitr::include_graphics(&quot;pics/rstudio_save_plots.gif&quot;) This is fine if you only generate one or two plots but if you generate a large number of them, it is less tedious to use the ggsave() function: my_plot1 = ggplot(my_data) + geom_bar(aes(variable)) ggsave(&quot;path/you/want/to/save/the/plot/to/my_plot1.pdf&quot;, my_plot1) There are other options that you can specify such as the width and height, resolution, units, etc… 6.4 Many plots In this section, we are going to learn how to use the possibilities offered by the purrr package and how it can work together with ggplot2 to generate many plots. This is a more advanced topic, but what comes next is also what makes R, and the functional programming paradigm so powerful. For example, suppose that instead of wanting a single plot with the unemployment rate of each commune, you need one unemployment plot, per commune: unemp_lux_data %&gt;% filter(division == &quot;Luxembourg&quot;) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division)) + theme_minimal() + labs(title = &quot;Unemployment in Luxembourg&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;) + geom_line() and then you would write the same for “Esch-sur-Alzette” and also for “Wiltz”. If you only have to make to make these 3 plots, copy and pasting the above lines is no big deal: unemp_lux_data %&gt;% filter(division == &quot;Esch-sur-Alzette&quot;) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division)) + theme_minimal() + labs(title = &quot;Unemployment in Esch-sur-Alzette&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;) + geom_line() unemp_lux_data %&gt;% filter(division == &quot;Wiltz&quot;) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division)) + theme_minimal() + labs(title = &quot;Unemployment in Esch-sur-Alzette&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;) + geom_line() Put copy and pasting is error prone. Can you spot the copy-paste mistake I made? And what if you have to create the above plots for all 108 Luxembourguish communes? That’s a lot of copy pasting. What if, once you are done copy pasting, you have to change something, for example, the theme? You could use the search and replace function of RStudio, true, but sometimes search and replace can also introduce bugs and typos. You can avoid all these issues by using purrr::map(). What do you need to map over? The commune names. So let’s create a vector of commune names: communes = list(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;) Now we can create the graphs using map(), or map2() to be exact: plots_tibble = unemp_lux_data %&gt;% filter(division %in% communes) %&gt;% group_by(division) %&gt;% nest() %&gt;% mutate(plot = map2(.x = data, .y = division, ~ggplot(data = .x) + theme_minimal() + geom_line(aes(year, unemployment_rate_in_percent, group = 1)) + labs(title = paste(&quot;Unemployment in&quot;, .y)))) Let’s study this line by line: the first line is easy, we simply use filter() to keep only the communes we are interested in. Then we group by division and use tidyr::nest(). As a refresher, let’s take a look at what this does: unemp_lux_data %&gt;% filter(division %in% communes) %&gt;% group_by(division) %&gt;% nest() ## # A tibble: 3 x 2 ## division data ## &lt;chr&gt; &lt;list&gt; ## 1 Esch-sur-Alzette &lt;tibble [15 x 7]&gt; ## 2 Luxembourg &lt;tibble [15 x 7]&gt; ## 3 Wiltz &lt;tibble [15 x 7]&gt; This creates a tibble with two columns, division and data, where each individual (or commune in this case) is another tibble with all the original variables. This is very useful, because now we can pass these tibbles to map2(), to generate the plots. But why map2() and what’s the difference with map()? map2() works the same way as map(), but maps over two inputs: numbers1 = list(1, 2, 3, 4, 5) numbers2 = list(9, 8, 7, 6, 5) map2(numbers1, numbers2, `*`) ## [[1]] ## [1] 9 ## ## [[2]] ## [1] 16 ## ## [[3]] ## [1] 21 ## ## [[4]] ## [1] 24 ## ## [[5]] ## [1] 25 In our example with the graphs, the two inputs are the data, and the names of the communes. This is useful to create the title with labs(title = paste(&quot;Unemployment in&quot;, .y)))) where .y is the second input of map2(), the commune names contained in variable division. So what happened? We now have a tibble called plots_tibble that looks like this: print(plots_tibble) ## # A tibble: 3 x 3 ## division data plot ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; ## 1 Esch-sur-Alzette &lt;tibble [15 x 7]&gt; &lt;S3: gg&gt; ## 2 Luxembourg &lt;tibble [15 x 7]&gt; &lt;S3: gg&gt; ## 3 Wiltz &lt;tibble [15 x 7]&gt; &lt;S3: gg&gt; This tibble contains three columns, division, data and now a new one called plot, that we created before using the last line mutate(plot = ...) (remember that mutate() adds columns to tibbles). plot is a list-column, with elements… being plots! Yes you read that right, the elements of the column plot are literally plots. This is what I meant with list columns. Let’s see what is inside the data and the plot columns exactly: plots_tibble %&gt;% pull(data) ## [[1]] ## # A tibble: 15 x 7 ## year active_population of_which_non_wage_earners of_which_wage_earners ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2001 11.339 665 10.113 ## 2 2002 11.675 677 10.302 ## 3 2003 11.718 674 10.231 ## 4 2004 12.187 659 10.629 ## 5 2005 11.944 654 10.338 ## 6 2006 12.233 657 10.510 ## 7 2007 12.558 634 10.893 ## 8 2008 12.869 638 10.955 ## 9 2009 13.236 652 11.007 ## 10 2010 13.555 638 11.183 ## 11 2011 13.869 630 11.469 ## 12 2012 14.344 684 11.831 ## 13 2013 14.779 694 12.031 ## 14 2014 15.152 703 12.452 ## 15 2015 15.341 710 12.600 ## # ... with 3 more variables: total_employed_population &lt;dbl&gt;, ## # unemployed &lt;dbl&gt;, unemployment_rate_in_percent &lt;dbl&gt; ## ## [[2]] ## # A tibble: 15 x 7 ## year active_population of_which_non_wage_earners of_which_wage_earners ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2001 34.391 2.891 30.357 ## 2 2002 34.802 2.939 30.298 ## 3 2003 35.195 3.030 30.130 ## 4 2004 35.561 3.059 30.110 ## 5 2005 35.611 3.134 29.833 ## 6 2006 35.454 3.118 30.309 ## 7 2007 36.133 3.254 31.118 ## 8 2008 37.510 3.393 31.885 ## 9 2009 37.924 3.487 31.590 ## 10 2010 38.626 3.543 32.123 ## 11 2011 40.326 3.660 33.552 ## 12 2012 41.824 3.810 34.640 ## 13 2013 43.368 3.982 35.531 ## 14 2014 44.604 4.107 36.661 ## 15 2015 45.221 4.140 37.510 ## # ... with 3 more variables: total_employed_population &lt;dbl&gt;, ## # unemployed &lt;dbl&gt;, unemployment_rate_in_percent &lt;dbl&gt; ## ## [[3]] ## # A tibble: 15 x 7 ## year active_population of_which_non_wage_earners of_which_wage_earners ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2001 2.131 223 1.786 ## 2 2002 2.138 220 1.784 ## 3 2003 2.180 223 1.794 ## 4 2004 2.237 227 1.854 ## 5 2005 2.263 229 1.847 ## 6 2006 2.202 206 1.815 ## 7 2007 2.273 198 1.878 ## 8 2008 2.298 200 1.897 ## 9 2009 2.362 201 1.945 ## 10 2010 2.423 195 1.972 ## 11 2011 2.476 190 2.017 ## 12 2012 2.588 188 2.099 ## 13 2013 2.662 195 2.149 ## 14 2014 2.692 185 2.192 ## 15 2015 2.771 180 2.270 ## # ... with 3 more variables: total_employed_population &lt;dbl&gt;, ## # unemployed &lt;dbl&gt;, unemployment_rate_in_percent &lt;dbl&gt; each element of data is a tibble for the specific country with columns year, active_population, etc, the original columns. But obviously, there is no division column. So to plot the data, and join all the dots together, we need to add group = 1 in the call to ggplot2() (whereas if you plot multiple lines in the same graph, you need to write group = division). But more interestingly, how can you actually see the plots? If you want to simply look at them, it is enough to use pull(): plots_tibble %&gt;% pull(plot) ## [[1]] ## ## [[2]] ## ## [[3]] And if we want to save these plots, we can do so using map2(): map2(paste0(plots_tibble$division, &quot;.pdf&quot;), plots_tibble$plot, ggsave) Saving 7 x 5 in image Saving 6.01 x 3.94 in image Saving 6.01 x 3.94 in image This was probably the most advanced topic we have studied yet; but you probably agree with me that it is among the most useful ones. This section is a perfect illustration of the power of functional programming; you can mix and match functions as long as you give them the correct arguments. You can pass data to functions that use data and then pass these functions to other functions that use functions as arguments, such as map().3 map() does not care if the functions you pass to it produces tables, graphs or even another function. map() will simply map this function to a list of inputs, and as long as these inputs are correct arguments to the function, map() will do its magic. If you combine this with list-columns, you can even use map() alongside dplyr functions and map your function by first grouping, filtering, etc… References "],
["statistical-models.html", "Chapter 7 Statistical models 7.1 Fitting a model to data 7.2 Diagnostics 7.3 Interpreting models 7.4 Comparing models 7.5 Using a model for prediction 7.6 Beyond linear regression 7.7 Advanced topics", " Chapter 7 Statistical models In this chapter, we will not learn about all the models out there that you may or may not need. Instead, I will show you how can use what you have learned until now and how you can apply these concepts to modeling. Also, as you read in the beginning of the book, R has many many packages. So the model you need is most probably already implemented in some package. 7.1 Fitting a model to data Suppose you have a variable y that you wish to explain using a set of other variables x1, x2, x3, etc. Let’s take a look at the Housing dataset from the Ecdat package: library(Ecdat) data(Housing) You can read a description of the dataset by running: ?Housing Housing package:Ecdat R Documentation Sales Prices of Houses in the City of Windsor Description: a cross-section from 1987 _number of observations_ : 546 _observation_ : goods _country_ : Canada Usage: data(Housing) Format: A dataframe containing : price: sale price of a house lotsize: the lot size of a property in square feet bedrooms: number of bedrooms bathrms: number of full bathrooms stories: number of stories excluding basement driveway: does the house has a driveway ? recroom: does the house has a recreational room ? fullbase: does the house has a full finished basement ? gashw: does the house uses gas for hot water heating ? airco: does the house has central air conditioning ? garagepl: number of garage places prefarea: is the house located in the preferred neighbourhood of the city ? Source: Anglin, P.M. and R. Gencay (1996) “Semiparametric estimation of a hedonic price function”, _Journal of Applied Econometrics_, *11(6)*, 633-648. References: Verbeek, Marno (2004) _A Guide to Modern Econometrics_, John Wiley and Sons, chapter 3. Journal of Applied Econometrics data archive : &lt;URL: http://qed.econ.queensu.ca/jae/&gt;. See Also: ‘Index.Source’, ‘Index.Economics’, ‘Index.Econometrics’, ‘Index.Observations’ or by looking for Housing in the help pane of RStudio. Usually, you would take a look a the data before doing any modeling: glimpse(Housing) ## Observations: 546 ## Variables: 12 ## $ price &lt;dbl&gt; 42000, 38500, 49500, 60500, 61000, 66000, 66000, 6900... ## $ lotsize &lt;dbl&gt; 5850, 4000, 3060, 6650, 6360, 4160, 3880, 4160, 4800,... ## $ bedrooms &lt;dbl&gt; 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 2, 3, 4,... ## $ bathrms &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1,... ## $ stories &lt;dbl&gt; 2, 1, 1, 2, 1, 1, 2, 3, 1, 4, 1, 1, 2, 1, 1, 1, 2, 3,... ## $ driveway &lt;fctr&gt; yes, yes, yes, yes, yes, yes, yes, yes, yes, yes, ye... ## $ recroom &lt;fctr&gt; no, no, no, yes, no, yes, no, no, yes, yes, no, no, ... ## $ fullbase &lt;fctr&gt; yes, no, no, no, no, yes, yes, no, yes, no, yes, no,... ## $ gashw &lt;fctr&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, ... ## $ airco &lt;fctr&gt; no, no, no, no, no, yes, no, no, no, yes, yes, no, n... ## $ garagepl &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 2, 0, 0, 1, 3, 0, 0, 0, 0, 0, 1, 0,... ## $ prefarea &lt;fctr&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, ... Housing prices depend on a set of variables such as the number of bedrooms, the area it is located and so on. If you believe that housing prices depend linearly on a set of explanatory variables, you will want to estimate a linear model. To estimate a linear model, you will need to use the built-in lm() function: model1 = lm(price ~ lotsize + bedrooms, data = Housing) lm() takes a formula as an argument, which defines the model you want to estimate. In this case, I ran the following regression: \\[ \\text{price} = \\alpha + \\beta_1 * \\text{lotsize} + \\beta_2 * \\text{bedrooms} + \\varepsilon \\] where \\(alpha, beta_1\\) and \\(beta_2\\) are three parameters to estimate. To take a look at the results, you can use the summary() method (not to be confused with dplyr::summarise(): summary(model1) ## ## Call: ## lm(formula = price ~ lotsize + bedrooms, data = Housing) ## ## Residuals: ## Min 1Q Median 3Q Max ## -65665 -12498 -2075 8970 97205 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 5.613e+03 4.103e+03 1.368 0.172 ## lotsize 6.053e+00 4.243e-01 14.265 &lt; 2e-16 *** ## bedrooms 1.057e+04 1.248e+03 8.470 2.31e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 21230 on 543 degrees of freedom ## Multiple R-squared: 0.3703, Adjusted R-squared: 0.3679 ## F-statistic: 159.6 on 2 and 543 DF, p-value: &lt; 2.2e-16 if you wish to remove the intercept (\\(alpha\\)) from your model, you can do so with -1: model2 = lm(price ~ -1 + lotsize + bedrooms, data = Housing) summary(model2) ## ## Call: ## lm(formula = price ~ -1 + lotsize + bedrooms, data = Housing) ## ## Residuals: ## Min 1Q Median 3Q Max ## -67229 -12342 -1333 9627 95509 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## lotsize 6.283 0.390 16.11 &lt;2e-16 *** ## bedrooms 11968.362 713.194 16.78 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 21250 on 544 degrees of freedom ## Multiple R-squared: 0.916, Adjusted R-squared: 0.9157 ## F-statistic: 2965 on 2 and 544 DF, p-value: &lt; 2.2e-16 or if you want to use all the columns inside Housing: model3 = lm(price ~ ., data = Housing) summary(model3) ## ## Call: ## lm(formula = price ~ ., data = Housing) ## ## Residuals: ## Min 1Q Median 3Q Max ## -41389 -9307 -591 7353 74875 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -4038.3504 3409.4713 -1.184 0.236762 ## lotsize 3.5463 0.3503 10.124 &lt; 2e-16 *** ## bedrooms 1832.0035 1047.0002 1.750 0.080733 . ## bathrms 14335.5585 1489.9209 9.622 &lt; 2e-16 *** ## stories 6556.9457 925.2899 7.086 4.37e-12 *** ## drivewayyes 6687.7789 2045.2458 3.270 0.001145 ** ## recroomyes 4511.2838 1899.9577 2.374 0.017929 * ## fullbaseyes 5452.3855 1588.0239 3.433 0.000642 *** ## gashwyes 12831.4063 3217.5971 3.988 7.60e-05 *** ## aircoyes 12632.8904 1555.0211 8.124 3.15e-15 *** ## garagepl 4244.8290 840.5442 5.050 6.07e-07 *** ## prefareayes 9369.5132 1669.0907 5.614 3.19e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 15420 on 534 degrees of freedom ## Multiple R-squared: 0.6731, Adjusted R-squared: 0.6664 ## F-statistic: 99.97 on 11 and 534 DF, p-value: &lt; 2.2e-16 You can access different elements of model3 (for example) with $, because the result of lm() is a list: print(model3$coefficients) ## (Intercept) lotsize bedrooms bathrms stories ## -4038.350425 3.546303 1832.003466 14335.558468 6556.945711 ## drivewayyes recroomyes fullbaseyes gashwyes aircoyes ## 6687.778890 4511.283826 5452.385539 12831.406266 12632.890405 ## garagepl prefareayes ## 4244.829004 9369.513239 but I prefer to use the broom package, and more specifically the tidy() function, which converts model3 into a neat data.frame: results3 = tidy(model3) glimpse(results3) ## Observations: 12 ## Variables: 5 ## $ term &lt;chr&gt; &quot;(Intercept)&quot;, &quot;lotsize&quot;, &quot;bedrooms&quot;, &quot;bathrms&quot;, &quot;st... ## $ estimate &lt;dbl&gt; -4038.350425, 3.546303, 1832.003466, 14335.558468, 6... ## $ std.error &lt;dbl&gt; 3409.4713, 0.3503, 1047.0002, 1489.9209, 925.2899, 2... ## $ statistic &lt;dbl&gt; -1.184451, 10.123618, 1.749764, 9.621691, 7.086369, ... ## $ p.value &lt;dbl&gt; 2.367616e-01, 3.732442e-22, 8.073341e-02, 2.570369e-... this is useful, because you can then work on the results easily, for example if you wish to only keep results that are significant at the 5% level: results3 %&gt;% filter(p.value &lt; 0.05) ## term estimate std.error statistic p.value ## 1 lotsize 3.546303 0.3503 10.123618 3.732442e-22 ## 2 bathrms 14335.558468 1489.9209 9.621691 2.570369e-20 ## 3 stories 6556.945711 925.2899 7.086369 4.374046e-12 ## 4 drivewayyes 6687.778890 2045.2458 3.269914 1.145151e-03 ## 5 recroomyes 4511.283826 1899.9577 2.374413 1.792936e-02 ## 6 fullbaseyes 5452.385539 1588.0239 3.433440 6.422381e-04 ## 7 gashwyes 12831.406266 3217.5971 3.987885 7.595575e-05 ## 8 aircoyes 12632.890405 1555.0211 8.123935 3.150681e-15 ## 9 garagepl 4244.829004 840.5442 5.050096 6.069790e-07 ## 10 prefareayes 9369.513239 1669.0907 5.613544 3.189602e-08 You can even add new columns, such as the confidence intervals: results3 = tidy(model3, conf.int = TRUE, conf.level = 0.95) print(results3) ## term estimate std.error statistic p.value conf.low ## 1 (Intercept) -4038.350425 3409.4713 -1.184451 2.367616e-01 -10735.971609 ## 2 lotsize 3.546303 0.3503 10.123618 3.732442e-22 2.858168 ## 3 bedrooms 1832.003466 1047.0002 1.749764 8.073341e-02 -224.740890 ## 4 bathrms 14335.558468 1489.9209 9.621691 2.570369e-20 11408.733579 ## 5 stories 6556.945711 925.2899 7.086369 4.374046e-12 4739.291087 ## 6 drivewayyes 6687.778890 2045.2458 3.269914 1.145151e-03 2670.064534 ## 7 recroomyes 4511.283826 1899.9577 2.374413 1.792936e-02 778.975864 ## 8 fullbaseyes 5452.385539 1588.0239 3.433440 6.422381e-04 2332.845419 ## 9 gashwyes 12831.406266 3217.5971 3.987885 7.595575e-05 6510.705975 ## 10 aircoyes 12632.890405 1555.0211 8.123935 3.150681e-15 9578.181593 ## 11 garagepl 4244.829004 840.5442 5.050096 6.069790e-07 2593.650266 ## 12 prefareayes 9369.513239 1669.0907 5.613544 3.189602e-08 6090.724248 ## conf.high ## 1 2659.270758 ## 2 4.234438 ## 3 3888.747822 ## 4 17262.383357 ## 5 8374.600336 ## 6 10705.493247 ## 7 8243.591788 ## 8 8571.925660 ## 9 19152.106558 ## 10 15687.599216 ## 11 5896.007742 ## 12 12648.302230 Going back to model estimation, you can of course use lm() in a pipe workflow: Housing %&gt;% select(-driveway, -stories) %&gt;% lm(price ~ ., data = .) %&gt;% tidy() ## term estimate std.error statistic p.value ## 1 (Intercept) 3025.444622 3262.7421099 0.9272705 3.542034e-01 ## 2 lotsize 3.667398 0.3631201 10.0996837 4.515215e-22 ## 3 bedrooms 4139.606144 1036.2909312 3.9946370 7.384906e-05 ## 4 bathrms 16443.499226 1546.3153358 10.6339883 4.293340e-24 ## 5 recroomyes 5659.653940 2010.1645778 2.8155177 5.049110e-03 ## 6 fullbaseyes 2241.223601 1618.2288335 1.3849856 1.666330e-01 ## 7 gashwyes 13568.262325 3411.4247037 3.9773008 7.927588e-05 ## 8 aircoyes 15578.013392 1597.3098060 9.7526562 8.528322e-21 ## 9 garagepl 4232.001307 882.8269365 4.7936930 2.123831e-06 ## 10 prefareayes 10728.842007 1753.2560499 6.1193811 1.814759e-09 The first . in the lm() function is used to indicate that we wish to use all the data from Housing (minus driveway and stories which I removed using select() and the - sign), and the second . is used to place the result from the two dplyr instructions that preceded is to be placed there. The picture below should help you understand: knitr::include_graphics(&quot;pics/pipe_to_second_position.png&quot;) You have to specify this, because by default, when using %&gt;% the left hand side argument gets passed as the first argument of the function on the right hand side. 7.2 Diagnostics Diagnostics are useful metrics to assess model fit. You can read some of these diagnostics, such as the \\(R^2\\) at the bottom of the summary (when running summary(my_model)), but if you want to do more than simply reading these diagnostics from RStudio, you can put those in a data.frame too, using broom::glance(): glance(model3) ## r.squared adj.r.squared sigma statistic p.value df logLik ## 1 0.6731236 0.6663902 15423.19 99.96774 6.177731e-122 12 -6034.094 ## AIC BIC deviance df.residual ## 1 12094.19 12150.12 127025071644 534 You can also plot the usual diagnostics plots using ggfortify::autoplot() which uses the ggplot2 package under the hood: library(ggfortify) autoplot(model3, which = 1:6) + theme_minimal() which=1:6 is an additional option that shows you all the diagnostics plot. If you omit this option, you will only get 4 of them. You can also get the residuals of the regression in two ways; either you grab them directly from the model fit: resi3 = residuals(model3) or you can augment the original data with a residuals column, using broom::augment(): housing_aug = augment(model3) Let’s take a look at housing_aug: glimpse(housing_aug) ## Observations: 546 ## Variables: 19 ## $ price &lt;dbl&gt; 42000, 38500, 49500, 60500, 61000, 66000, 66000, 69... ## $ lotsize &lt;dbl&gt; 5850, 4000, 3060, 6650, 6360, 4160, 3880, 4160, 480... ## $ bedrooms &lt;dbl&gt; 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 2, 3, ... ## $ bathrms &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, ... ## $ stories &lt;dbl&gt; 2, 1, 1, 2, 1, 1, 2, 3, 1, 4, 1, 1, 2, 1, 1, 1, 2, ... ## $ driveway &lt;fctr&gt; yes, yes, yes, yes, yes, yes, yes, yes, yes, yes, ... ## $ recroom &lt;fctr&gt; no, no, no, yes, no, yes, no, no, yes, yes, no, no... ## $ fullbase &lt;fctr&gt; yes, no, no, no, no, yes, yes, no, yes, no, yes, n... ## $ gashw &lt;fctr&gt; no, no, no, no, no, no, no, no, no, no, no, no, no... ## $ airco &lt;fctr&gt; no, no, no, no, no, yes, no, no, no, yes, yes, no,... ## $ garagepl &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 2, 0, 0, 1, 3, 0, 0, 0, 0, 0, 1, ... ## $ prefarea &lt;fctr&gt; no, no, no, no, no, no, no, no, no, no, no, no, no... ## $ .fitted &lt;dbl&gt; 66037.98, 41391.15, 39889.63, 63689.09, 49760.43, 6... ## $ .se.fit &lt;dbl&gt; 1790.507, 1406.500, 1534.102, 2262.056, 1567.689, 2... ## $ .resid &lt;dbl&gt; -24037.9757, -2891.1515, 9610.3699, -3189.0873, 112... ## $ .hat &lt;dbl&gt; 0.013477335, 0.008316321, 0.009893730, 0.021510891,... ## $ .sigma &lt;dbl&gt; 15402.01, 15437.14, 15431.98, 15437.02, 15429.89, 1... ## $ .cooksd &lt;dbl&gt; 2.803214e-03, 2.476265e-05, 3.265481e-04, 8.004787e... ## $ .std.resid &lt;dbl&gt; -1.56917096, -0.18823924, 0.62621736, -0.20903274, ... A few columns have been added to the original data, among them .resid which contains the residuals. Let’s plot them: ggplot(housing_aug) + geom_density(aes(.resid)) Fitted values are also added to the original data, under the variable .fitted. It would also have been possible to get the fitted values with: fit3 = fitted(model3) but I prefer using augment(), because the columns get merged to the original data, which then makes it easier to find specific individuals, for example, you might want to know for which housing units the model underestimates the price: total_pos = housing_aug %&gt;% filter(.resid &gt; 0) %&gt;% summarise(total = n()) %&gt;% pull(total) we find 261 individuals where the residuals are positive. It is also easier to extract outliers: housing_aug %&gt;% mutate(prank = cume_dist(.cooksd)) %&gt;% filter(prank &gt; 0.99) %&gt;% glimpse() ## Observations: 6 ## Variables: 20 ## $ price &lt;dbl&gt; 163000, 125000, 132000, 175000, 190000, 174500 ## $ lotsize &lt;dbl&gt; 7420, 4320, 3500, 9960, 7420, 7500 ## $ bedrooms &lt;dbl&gt; 4, 3, 4, 3, 4, 4 ## $ bathrms &lt;dbl&gt; 1, 1, 2, 2, 2, 2 ## $ stories &lt;dbl&gt; 2, 2, 2, 2, 3, 2 ## $ driveway &lt;fctr&gt; yes, yes, yes, yes, yes, yes ## $ recroom &lt;fctr&gt; yes, no, no, no, no, no ## $ fullbase &lt;fctr&gt; yes, yes, no, yes, no, yes ## $ gashw &lt;fctr&gt; no, yes, yes, no, no, no ## $ airco &lt;fctr&gt; yes, no, no, no, yes, yes ## $ garagepl &lt;dbl&gt; 2, 2, 2, 2, 2, 3 ## $ prefarea &lt;fctr&gt; no, no, no, yes, yes, yes ## $ .fitted &lt;dbl&gt; 94826.68, 77688.37, 85495.58, 108563.18, 115125.03,... ## $ .se.fit &lt;dbl&gt; 2520.691, 3551.954, 3544.961, 2589.680, 2185.603, 2... ## $ .resid &lt;dbl&gt; 68173.32, 47311.63, 46504.42, 66436.82, 74874.97, 5... ## $ .hat &lt;dbl&gt; 0.02671105, 0.05303793, 0.05282929, 0.02819317, 0.0... ## $ .sigma &lt;dbl&gt; 15144.70, 15293.34, 15298.27, 15159.14, 15085.99, 1... ## $ .cooksd &lt;dbl&gt; 0.04590995, 0.04637969, 0.04461464, 0.04616068, 0.0... ## $ .std.resid &lt;dbl&gt; 4.480428, 3.152300, 3.098176, 4.369631, 4.904193, 3... ## $ prank &lt;dbl&gt; 0.9963370, 1.0000000, 0.9945055, 0.9981685, 0.99267... prank is a variable I created with cume_dist() which is a dplyr function that returns the proportion of all values less than or equal to the current rank. For example: example = c(5, 4.6, 2, 1, 0.8, 0, -1) cume_dist(example) ## [1] 1.0000000 0.8571429 0.7142857 0.5714286 0.4285714 0.2857143 0.1428571 by filtering prank &gt; 0.99 we get the top 1% of outliers according to Cook’s distance. 7.3 Interpreting models Model interpretation is essential in the social sciences. If one wants to know the effect of variable x on the dependent variable y, marginal effects have to be computed. This is easily done in R with the margins package, which aims to provide the same functionality as the margins command in STATA: library(margins) effects_model3 = margins(model3) summary(effects_model3) ## factor AME SE z p lower upper ## aircoyes 12632.8904 1555.0329 8.1239 0.0000 9585.0819 15680.6989 ## bathrms 14335.5585 1482.9885 9.6667 0.0000 11428.9545 17242.1624 ## bedrooms 1832.0035 1045.6558 1.7520 0.0798 -217.4442 3881.4512 ## drivewayyes 6687.7789 2045.2636 3.2699 0.0011 2679.1359 10696.4219 ## fullbaseyes 5452.3855 1587.9782 3.4335 0.0006 2340.0054 8564.7657 ## garagepl 4244.8290 847.2173 5.0103 0.0000 2584.3136 5905.3444 ## gashwyes 12831.4063 3217.6211 3.9879 0.0001 6524.9848 19137.8277 ## lotsize 3.5463 0.3503 10.1250 0.0000 2.8598 4.2328 ## prefareayes 9369.5132 1669.1034 5.6135 0.0000 6098.1307 12640.8957 ## recroomyes 4511.2838 1899.9255 2.3745 0.0176 787.4982 8235.0694 ## stories 6556.9457 924.4211 7.0930 0.0000 4745.1137 8368.7777 It is also possible to plot the results: plot(effects_model3) This uses the basic R plotting capabilities, which is useful because it is a simple call to the function plot() but if you’ve been using ggplot2 and want this graph to have the same feel as the others made with ggplot2 you first need to save the summary in a variable. summary(effects_model3) is a data.frame with many more details. Let’s overwrite this effects_model3 with its summary: effects_model3 = summary(effects_model3) And now it is possible to use ggplot2 to have the same plot: ggplot(data = effects_model3) + geom_point(aes(factor, AME)) + geom_errorbar(aes(x = factor, ymin = lower, ymax = upper)) + geom_hline(yintercept = 0) + theme_minimal() + theme(axis.text.x = element_text(angle = 45)) Of course for model3, the marginal effects are the same as the coefficients, so let’s estimate a logit model and compute the marginal effects. Logit models can be estimated using the glm() function. As an example, we are going to use the Participation data, also from the Ecdat package: data(Participation) ?Particpation Participation package:Ecdat R Documentation Labor Force Participation Description: a cross-section _number of observations_ : 872 _observation_ : individuals _country_ : Switzerland Usage: data(Participation) Format: A dataframe containing : lfp labour force participation ? lnnlinc the log of nonlabour income age age in years divided by 10 educ years of formal education nyc the number of young children (younger than 7) noc number of older children foreign foreigner ? Source: Gerfin, Michael (1996) “Parametric and semiparametric estimation of the binary response”, _Journal of Applied Econometrics_, *11(3)*, 321-340. References: Davidson, R. and James G. MacKinnon (2004) _Econometric Theory and Methods_, New York, Oxford University Press, &lt;URL: http://www.econ.queensu.ca/ETM/&gt;, chapter 11. Journal of Applied Econometrics data archive : &lt;URL: http://qed.econ.queensu.ca/jae/&gt;. See Also: ‘Index.Source’, ‘Index.Economics’, ‘Index.Econometrics’, ‘Index.Observations’ The variable of interest is lfp: whether the individual participates in the labour force. To know which variables are relevant in the decision to participate in the labour force, one could estimate a logit model, using glm(). logit_participation = glm(lfp ~ ., data = Participation, family = &quot;binomial&quot;) tidy(logit_participation) ## term estimate std.error statistic p.value ## 1 (Intercept) 10.37434616 2.16685216 4.7877499 1.686617e-06 ## 2 lnnlinc -0.81504064 0.20550116 -3.9661122 7.305449e-05 ## 3 age -0.51032975 0.09051783 -5.6378920 1.721444e-08 ## 4 educ 0.03172803 0.02903580 1.0927211 2.745163e-01 ## 5 nyc -1.33072362 0.18017027 -7.3859224 1.514000e-13 ## 6 noc -0.02198573 0.07376636 -0.2980454 7.656685e-01 ## 7 foreignyes 1.31040497 0.19975784 6.5599678 5.381941e-11 From the results above, one can only interpret the sign of the coefficients. To know how much a variable influences the labour force participation, one has to use margins(): effects_logit_participation = margins(logit_participation) %&gt;% summary() ## Warning in warn_for_weights(model): &#39;weights&#39; used in model estimation are ## currently ignored! print(effects_logit_participation) ## factor AME SE z p lower upper ## age -0.1064 0.0176 -6.0494 0.0000 -0.1409 -0.0719 ## educ 0.0066 0.0060 1.0955 0.2733 -0.0052 0.0185 ## foreignyes 0.2834 0.0399 7.1102 0.0000 0.2053 0.3615 ## lnnlinc -0.1699 0.0415 -4.0994 0.0000 -0.2512 -0.0887 ## noc -0.0046 0.0154 -0.2981 0.7656 -0.0347 0.0256 ## nyc -0.2775 0.0333 -8.3433 0.0000 -0.3426 -0.2123 We can use the previous code to plot the marginal effects: ggplot(data = effects_logit_participation) + geom_point(aes(factor, AME)) + geom_errorbar(aes(x = factor, ymin = lower, ymax = upper)) + geom_hline(yintercept = 0) + theme_minimal() + theme(axis.text.x = element_text(angle = 45)) So an infinitesimal increase, in say, non-labour income (lnnlinc) of 0.001 is associated with a decrease of the probability of labour force participation by 0.001*17 percentage points. You can also extract the marginal effects of a single variable: head(dydx(Participation, logit_participation, &quot;lnnlinc&quot;)) ## dydx_lnnlinc ## 1 -0.15667764 ## 2 -0.20014487 ## 3 -0.18495109 ## 4 -0.05377262 ## 5 -0.18710476 ## 6 -0.19586986 Which makes it possible to extract the effect for a list of individuals that you can create yourself: my_subjects = tribble( ~lfp, ~lnnlinc, ~age, ~educ, ~nyc, ~noc, ~foreign, &quot;yes&quot;, 10.780, 7.0, 4, 1, 1, &quot;yes&quot;, &quot;no&quot;, 1.30, 9.0, 1, 4, 1, &quot;yes&quot; ) dydx(my_subjects, logit_participation, &quot;lnnlinc&quot;) ## dydx_lnnlinc ## 1 -0.09228119 ## 2 -0.17953451 I used the tribble() function from the tibble package to create this test data set, row by row. Then, using dydx(), I get the marginal effect of variable lnnlinc for these two individuals. 7.4 Comparing models Let’s estimate another model on the same data; prices are only positive, so a linear regression might not be the best model, because the model allows for negative prices. Let’s look at the distribution of prices: ggplot(Housing) + geom_density(aes(price)) it looks like modeling the log of price might provide a better fit: model_log = lm(log(price) ~ ., data = Housing) result_log = tidy(model_log) print(result_log) ## term estimate std.error statistic p.value ## 1 (Intercept) 1.002556e+01 4.724349e-02 212.210317 0.000000e+00 ## 2 lotsize 5.057053e-05 4.853947e-06 10.418435 2.908737e-23 ## 3 bedrooms 3.402048e-02 1.450780e-02 2.344978 1.939345e-02 ## 4 bathrms 1.677687e-01 2.064515e-02 8.126299 3.096505e-15 ## 5 stories 9.227447e-02 1.282132e-02 7.196956 2.098439e-12 ## 6 drivewayyes 1.306513e-01 2.834004e-02 4.610130 5.040563e-06 ## 7 recroomyes 7.351654e-02 2.632685e-02 2.792455 5.418509e-03 ## 8 fullbaseyes 9.939967e-02 2.200452e-02 4.517238 7.717764e-06 ## 9 gashwyes 1.783545e-01 4.458477e-02 4.000347 7.217517e-05 ## 10 aircoyes 1.780197e-01 2.154722e-02 8.261841 1.138204e-15 ## 11 garagepl 5.075683e-02 1.164704e-02 4.357918 1.575321e-05 ## 12 prefareayes 1.271134e-01 2.312783e-02 5.496122 6.021383e-08 Let’s take a look at the diagnostics: glance(model_log) ## r.squared adj.r.squared sigma statistic p.value df logLik ## 1 0.676591 0.669929 0.2137121 101.56 3.666219e-123 12 73.87312 ## AIC BIC deviance df.residual ## 1 -121.7462 -65.81219 24.3893 534 Let’s compare these to the ones from the previous model: diag_lm = glance(model3) diag_lm = diag_lm %&gt;% mutate(model = &quot;lin-lin model&quot;) diag_log = glance(model_log) diag_log = diag_log %&gt;% mutate(model = &quot;log-lin model&quot;) diagnostics_models = full_join(diag_lm, diag_log) ## Joining, by = c(&quot;r.squared&quot;, &quot;adj.r.squared&quot;, &quot;sigma&quot;, &quot;statistic&quot;, &quot;p.value&quot;, &quot;df&quot;, &quot;logLik&quot;, &quot;AIC&quot;, &quot;BIC&quot;, &quot;deviance&quot;, &quot;df.residual&quot;, &quot;model&quot;) print(diagnostics_models) ## r.squared adj.r.squared sigma statistic p.value df ## 1 0.6731236 0.6663902 1.542319e+04 99.96774 6.177731e-122 12 ## 2 0.6765910 0.6699290 2.137121e-01 101.56000 3.666219e-123 12 ## logLik AIC BIC deviance df.residual ## 1 -6034.09400 12094.1880 12150.12204 1.270251e+11 534 ## 2 73.87312 -121.7462 -65.81219 2.438930e+01 534 ## model ## 1 lin-lin model ## 2 log-lin model I saved the diagnostics in two different data.frame using the glance() function and added a model column to indicate which model the diagnostics come from. Then I merged both datasets using full_join(), a dplyr function. As you can see, the model with the logarithm of the prices as the explained variable has a higher likelihood (and thus lower AIC and BIC) than the simple linear model. Let’s take a look at the diagnostics plots: autoplot(model_log, which = 1:6) + theme_minimal() 7.5 Using a model for prediction Once you estimated a model, you might want to use it for prediction. This is easily done using the predict() function that works with most models. Prediction is also useful as a way to test the accuracy of your model: split your data into a training set (used for estimation) and a testing set (used for the pseudo-prediction) and see if your model overfits the data. We are going to see how to do that in a later section; for now, let’s just get acquainted with predict(). Let’s go back to the models we estimated in the previous section, model3 and model_log. Let’s also take a subsample of data, which we will be using for prediction: set.seed(1234) pred_set = Housing %&gt;% sample_n(20) so that we get always the same pred_set I set the random seed first. Let’s take a look at the data: print(pred_set) ## price lotsize bedrooms bathrms stories driveway recroom fullbase ## 63 52000 4280 2 1 1 yes no no ## 340 62500 3900 3 1 2 yes no no ## 332 175000 8960 4 4 4 yes no no ## 339 141000 8100 4 1 2 yes yes yes ## 467 54000 2856 3 1 3 yes no no ## 347 52000 4130 3 2 2 yes no no ## 6 66000 4160 3 1 1 yes yes yes ## 126 95000 4260 4 2 2 yes no no ## 359 97000 12090 4 2 2 yes no no ## 277 70000 6300 3 1 1 yes no no ## 372 85000 6420 3 1 1 yes no yes ## 292 39000 4000 3 1 2 yes no no ## 151 59900 3450 3 1 2 yes no no ## 493 53000 4050 2 1 1 yes no no ## 156 60000 2610 4 3 2 no no no ## 445 72500 5720 2 1 2 yes no no ## 152 35500 3000 3 1 2 no no no ## 142 40000 2650 3 1 2 yes no yes ## 99 35000 3500 2 1 1 yes yes no ## 123 37000 4400 2 1 1 yes no no ## gashw airco garagepl prefarea ## 63 no yes 2 no ## 340 no no 0 no ## 332 no yes 3 no ## 339 no yes 2 yes ## 467 no no 0 yes ## 347 no no 2 no ## 6 no yes 0 no ## 126 yes no 0 no ## 359 no no 2 yes ## 277 no yes 2 no ## 372 no yes 0 yes ## 292 no no 1 no ## 151 no no 1 no ## 493 no no 0 no ## 156 no no 0 no ## 445 no yes 0 yes ## 152 no no 0 no ## 142 no no 1 no ## 99 no no 0 no ## 123 no no 0 no If we wish to use it for prediction, this is easily done with predict(): predict(model3, pred_set) ## 63 340 332 339 467 347 6 ## 63506.66 49425.47 150689.71 106607.68 61649.59 73066.34 66387.12 ## 126 359 277 372 292 151 493 ## 79701.11 112496.42 72502.20 79260.00 54024.93 52074.46 41568.47 ## 156 445 152 142 99 123 ## 68666.08 76050.14 39546.02 54689.81 44129.28 42809.67 This returns a vector of predicted prices. This can then be used to compute the Root Mean Squared Error for instance. Let’s do it within a tidyverse pipeline: rmse = pred_set %&gt;% mutate(predictions = predict(model3, .)) %&gt;% summarise(sqrt(sum(predictions - price)**2/n())) The root mean square error of model3 is 1666.1312666. I also use the n() function which returns the number of observations in a group (or all the observations, if the data is not grouped). Let’s compare model3 ’s RMSE with the one from model_log: rmse2 = pred_set %&gt;% mutate(predictions = exp(predict(model_log, .))) %&gt;% summarise(sqrt(sum(predictions - price)**2/n())) Don’t forget to exponentiate the predictions, remember you’re dealing with a log-linear model! model_log’s RMSE is 1359.0392252 which is lower than model3’s. However, keep in mind that the model was estimated on the whole data, and then the prediction quality was assessed using a subsample of the data the model was estimated on… so actually we can’t really say if model_log’s predictions are very useful. Of course, this is the same for model3. In a later section we are going to learn how to do cross validation to avoid this issue. Also another problem of what I did before, unrelated to statistics per se, is that I wanted to compute the same quantity for two different models, and did so by copy and pasting 3 lines of code. That’s not much, but if I wanted to compare 10 models, copy and paste mistakes could have sneaked in. Instead, it would have been nice to have a function that computes the RMSE and then use it on my models. We are going to learn how to write our own function and use it just like if it was another built-in R function. 7.6 Beyond linear regression R has a lot of other built-in functions for regression, such as glm() (for Generalized Linear Models) and nls() for (for Nonlinear Least Squares). There are also functions and additional packages for time series, panel data, machine learning, bayesian and nonparametric methods. Presenting everything here would take too much space, and would be pretty useless as you can find whatever you need using an internet search engine. What you have learned until now is quite general and should work on many type of models. To help you out, here is a list of methods and the recommended packages that you can use: Model Package Quick example Robust Linear Regression MASS rlm(y ~ x, data = mydata) Nonlinear Least Squares stats4 nls(y ~ x1 / (1 + x2), data = mydata)5 Logit stats glm(y ~ x, data = mydata, family = &quot;binomial&quot;) Probit stats glm(y ~ x, data = mydata, family = binomial(link = &quot;probit&quot;)) K-Means stats kmeans(data, n)6 PCA stats prcomp(data, scale = TRUE, center = TRUE)7 Multinomial Logit mlogit Requires several steps of data pre-processing and formula definition, refer to the Vignette for more details. Cox PH survival coxph(Surv(y_time, y_status) ~ x, data = mydata)8 Time series Several, depending on your needs. Time series in R is a vast subject that would require a very thick book to cover. You can get started with the following series of blog articles, Tidy time-series, part 1, Tidy time-series, part 2, Tidy time-series, part 3 and Tidy time-series, part 3 Panel data plm plm(y ~ x, data = mydata, model = &quot;within|random&quot;) Neural Networks Several, depending on your needs. R is a very popular programming language for machine learning. This blog post lists and compares some of the most useful packages for Neural nets and deep learning. Nonparametric regression np Several functions and options available, refer to the Vignette for more details. I put neural networks in the table, but you can also find packages for regression trees, naive bayes, and pretty much any machine learning method out there! The same goes for Bayesian methods. Popular packages include rstan, rjags which link R to STAN and JAGS (two other pieces of software that do the Gibbs sampling for you) which are tools that allow you to fit very general models. It is also possible to estimate models using Bayesian inference without the need of external tools, with the bayesm package which estimates the usual micro-econometric models. There really are a lot of packages available for Bayesian inference, and you can find them all in the related CRAN Task View. 7.7 Advanced topics 7.7.1 Bootstrapping The broom package includes a bootstrap() function that allows you to resample your data with replacement and estimate your model on each sample. A worked example is available in one of the package’s Vignette. R also includes a more general boot() function, but we are going to learn about this one later, as it involves some programming. Let’s go back to model_log, and try to get bootstrapped confidence intervals (as shown in the Vignette I linked above): boot_result = Housing %&gt;% bootstrap(50) %&gt;% do(tidy(lm(log(price) ~ bedrooms + driveway, data = .))) I just use 2 variables to make the output smaller. Let’s take a look at boot_result: print(boot_result) ## # A tibble: 150 x 6 ## # Groups: replicate [50] ## replicate term estimate std.error statistic p.value ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 (Intercept) 10.2691480 0.06612497 155.299091 0.000000e+00 ## 2 1 bedrooms 0.1653885 0.01834047 9.017679 3.289600e-18 ## 3 1 drivewayyes 0.3422638 0.03879711 8.821890 1.537261e-17 ## 4 2 (Intercept) 10.1079413 0.06624453 152.585303 0.000000e+00 ## 5 2 bedrooms 0.2325295 0.01853996 12.542069 7.224885e-32 ## 6 2 drivewayyes 0.3196658 0.03952153 8.088397 3.969076e-15 ## 7 3 (Intercept) 10.1945652 0.06741861 151.212929 0.000000e+00 ## 8 3 bedrooms 0.1996018 0.01955275 10.208379 1.682842e-22 ## 9 3 drivewayyes 0.3056554 0.03868654 7.900821 1.549478e-14 ## 10 4 (Intercept) 10.2896575 0.06921918 148.653275 0.000000e+00 ## # ... with 140 more rows boot_result is a tibble grouped by the new variable replicate. Now it is easy to compute confidence intervals for the parameters: boot_result %&gt;% group_by(term) %&gt;% summarize(low = quantile(estimate, .05/2), high = quantile(estimate, 1 - .05/2)) ## # A tibble: 3 x 3 ## term low high ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 bedrooms 0.1471192 0.2252752 ## 2 drivewayyes 0.3060920 0.4194924 ## 3 (Intercept) 10.0622613 10.3195883 quantile() is a built-in function that returns the quantile at the \\(alpha\\) level for a given vector (in this case the vector of estimates). Of course, we had to group by term first, as we need to compute the confidence intervals, for each terms (or estimated parameters) separately. Plotting the densities of the bootstrapped parameters might also prove interesting: ggplot(boot_result, aes(estimate)) + geom_density() + facet_wrap(~term, scales = &quot;free&quot;) 7.7.2 Cross-validation To do cross-validation, we are going to use the modelr package, which is also part of the tidyverse.9 library(modelr) ## ## Attaching package: &#39;modelr&#39; ## The following object is masked from &#39;package:broom&#39;: ## ## bootstrap modelr includes two functions for cross-validation, crossv_kfold and crossv_mc, which do K-fold Cross-Validation and Monte Carlo Cross-Validation respectively. First, let’s see what cross_mc() (cross_kfold()) returns when applied to data: cv_Housing = Housing %&gt;% crossv_mc(n = 50) print(cv_Housing) ## # A tibble: 50 x 3 ## train test .id ## &lt;list&gt; &lt;list&gt; &lt;chr&gt; ## 1 &lt;S3: resample&gt; &lt;S3: resample&gt; 01 ## 2 &lt;S3: resample&gt; &lt;S3: resample&gt; 02 ## 3 &lt;S3: resample&gt; &lt;S3: resample&gt; 03 ## 4 &lt;S3: resample&gt; &lt;S3: resample&gt; 04 ## 5 &lt;S3: resample&gt; &lt;S3: resample&gt; 05 ## 6 &lt;S3: resample&gt; &lt;S3: resample&gt; 06 ## 7 &lt;S3: resample&gt; &lt;S3: resample&gt; 07 ## 8 &lt;S3: resample&gt; &lt;S3: resample&gt; 08 ## 9 &lt;S3: resample&gt; &lt;S3: resample&gt; 09 ## 10 &lt;S3: resample&gt; &lt;S3: resample&gt; 10 ## # ... with 40 more rows This is a tibble with 3 colmuns, two of them being list-columns; train and test. Each element of train and test is a resampled tibble of the original data. This means that we can now estimate our first model (the simple linear one) on each resampled data using map(): Now if we want to estimate all these models: cv_models = cv_Housing %&gt;% mutate(model = map(train, ~lm(price ~ ., data = .))) print(cv_models) ## # A tibble: 50 x 4 ## train test .id model ## &lt;list&gt; &lt;list&gt; &lt;chr&gt; &lt;list&gt; ## 1 &lt;S3: resample&gt; &lt;S3: resample&gt; 01 &lt;S3: lm&gt; ## 2 &lt;S3: resample&gt; &lt;S3: resample&gt; 02 &lt;S3: lm&gt; ## 3 &lt;S3: resample&gt; &lt;S3: resample&gt; 03 &lt;S3: lm&gt; ## 4 &lt;S3: resample&gt; &lt;S3: resample&gt; 04 &lt;S3: lm&gt; ## 5 &lt;S3: resample&gt; &lt;S3: resample&gt; 05 &lt;S3: lm&gt; ## 6 &lt;S3: resample&gt; &lt;S3: resample&gt; 06 &lt;S3: lm&gt; ## 7 &lt;S3: resample&gt; &lt;S3: resample&gt; 07 &lt;S3: lm&gt; ## 8 &lt;S3: resample&gt; &lt;S3: resample&gt; 08 &lt;S3: lm&gt; ## 9 &lt;S3: resample&gt; &lt;S3: resample&gt; 09 &lt;S3: lm&gt; ## 10 &lt;S3: resample&gt; &lt;S3: resample&gt; 10 &lt;S3: lm&gt; ## # ... with 40 more rows We added a list-column with the 50 models estimated (or trained) on the train data. Now we can compute, say, the RMSE from before on each one. modelr includes a rmse() function, so unlike in the previous section where we computed the RMSE manually we are simply going to use this function: rmse_cv = cv_models %&gt;% mutate(rmse_all_models = map2_dbl(model, test, ~rmse(.x, .y))) %&gt;% pull(rmse_all_models) print(rmse_cv) ## [1] 14278.10 16319.37 15894.75 13787.08 17718.08 13909.55 18768.75 ## [8] 14207.10 15035.37 14517.33 16683.72 15840.99 15367.34 14712.03 ## [15] 15700.72 15471.62 17671.22 17406.67 17202.93 15583.84 14194.29 ## [22] 17172.91 14780.65 15209.08 14574.40 15488.37 14615.14 17109.50 ## [29] 16463.38 16483.56 14267.87 16318.03 14574.68 18505.86 15049.98 ## [36] 14062.81 15659.73 15739.34 14316.86 16180.04 18592.96 18135.36 ## [43] 15166.21 17783.14 16475.84 16012.22 12702.82 16545.16 15420.06 ## [50] 15109.43 We can now compute the mean of this rmse_cv variable: cv_rmse_lin_lin = mean(rmse_cv) which is equal to 1.577572510^{4}. For the log-lin model, this is a bit more complicated, because we need to exponentiate the predictions. However, if we use rmse() as before, there is no way to do that. I show you how you can do that, but it involves a few more steps than simply using rmse(). Try to understand the code below that computes the bootstrapped rmse for the log-lin model. You can see this as an advanced exercise; if you understand these next lines of code, you should understand anything that has to do with the tidyverse. cv_rmse_log_lin = cv_Housing %&gt;% mutate(model = map(train, ~lm(log(price) ~ ., data = .))) %&gt;% mutate(log_pred = map2(model, test, ~exp(predict(.x, .y)))) %&gt;% mutate(prices = map(test, ~as.data.frame(.x)$price)) %&gt;% mutate( rmse_all = map2_dbl(log_pred, prices, ~sqrt(mean((.x - .y)**2, na.rm = TRUE)))) %&gt;% pull(rmse_all) %&gt;% mean() cv_rmse_log_lin is equal to 1.551068110^{4}, which is lower than in the lin-lin model. This package gets installed with R, no need to add it↩ The formula in the example is shown for illustration purposes.↩ data must only contain numeric values, and n is the number of clusters.↩ data must only contain numeric values, or a formula can be provided.↩ Surv(y_time, y_status) creates a survival object, where y_time is the time to event y_status. It is possible to create more complex survival objects depending on exactly which data you are dealing with.↩ This package is still somewhat young and experimental and might get replaced by two others in the future. At some point in the future you might get a warning message telling you that the package is deprecated. When this happens, you would need to switch to the new packages, but transition should be fairly easy.↩ "],
["advanced-topics-1.html", "Chapter 8 Advanced topics 8.1 For and while loops 8.2 Programming your own functions 8.3 Generating Pdf or Word reports with R 8.4 Scraping the internet 8.5 Writing your own package 8.6 Random tips and tricks", " Chapter 8 Advanced topics 8.1 For and while loops 8.2 Programming your own functions Before merging these datasets together, we would need them to have a year column indicating the year. It would also be helpful if gave names to these datasets. For this task, we can use purrr::set_names(): all_datasets = set_names(all_datasets, as.character(seq(2013, 2016))) Let’s take a look at the list now: str(all_datasets) ## List of 4 ## $ 2013:&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ total_employed_population : int [1:118] 223407 17802 1703 844 1431 4094 2146 971 1218 3002 ... ## ..$ of_which_wage_earners : int [1:118] 203535 15993 1535 750 1315 3800 1874 858 1029 2664 ... ## ..$ of_which_non_wage_earners : int [1:118] 19872 1809 168 94 116 294 272 113 189 338 ... ## ..$ unemployed : int [1:118] 19287 1071 114 25 74 261 98 45 66 207 ... ## ..$ active_population : int [1:118] 242694 18873 1817 869 1505 4355 2244 1016 1284 3209 ... ## ..$ unemployment_rate_in_percent: num [1:118] 7.95 5.67 6.27 2.88 4.92 ... ## ..$ year : int [1:118] 2013 2013 2013 2013 2013 2013 2013 2013 2013 2013 ... ## $ 2014:&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ total_employed_population : int [1:118] 228423 18166 1767 845 1505 4129 2172 1007 1268 3124 ... ## ..$ of_which_wage_earners : int [1:118] 208238 16366 1606 757 1390 3840 1897 887 1082 2782 ... ## ..$ of_which_non_wage_earners : int [1:118] 20185 1800 161 88 115 289 275 120 186 342 ... ## ..$ unemployed : int [1:118] 19362 1066 122 19 66 287 91 38 61 202 ... ## ..$ active_population : int [1:118] 247785 19232 1889 864 1571 4416 2263 1045 1329 3326 ... ## ..$ unemployment_rate_in_percent: num [1:118] 7.81 5.54 6.46 2.2 4.2 ... ## ..$ year : int [1:118] 2014 2014 2014 2014 2014 2014 2014 2014 2014 2014 ... ## $ 2015:&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ total_employed_population : int [1:118] 233130 18310 1780 870 1470 4130 2170 1050 1300 3140 ... ## ..$ of_which_wage_earners : int [1:118] 212530 16430 1620 780 1350 3820 1910 920 1100 2770 ... ## ..$ of_which_non_wage_earners : int [1:118] 20600 1880 160 90 120 310 260 130 200 370 ... ## ..$ unemployed : int [1:118] 18806 988 106 29 73 260 80 41 72 169 ... ## ..$ active_population : int [1:118] 251936 19298 1886 899 1543 4390 2250 1091 1372 3309 ... ## ..$ unemployment_rate_in_percent: num [1:118] 7.46 5.12 5.62 3.23 4.73 ... ## ..$ year : int [1:118] 2015 2015 2015 2015 2015 2015 2015 2015 2015 2015 ... ## $ 2016:&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ total_employed_population : int [1:118] 236100 18380 1790 870 1470 4160 2160 1030 1330 3150 ... ## ..$ of_which_wage_earners : int [1:118] 215430 16500 1640 780 1350 3840 1900 900 1130 2780 ... ## ..$ of_which_non_wage_earners : int [1:118] 20670 1880 150 90 120 320 260 130 200 370 ... ## ..$ unemployed : int [1:118] 18185 975 91 27 66 246 76 35 70 206 ... ## ..$ active_population : int [1:118] 254285 19355 1881 897 1536 4406 2236 1065 1400 3356 ... ## ..$ unemployment_rate_in_percent: num [1:118] 7.15 5.04 4.84 3.01 4.3 ... ## ..$ year : int [1:118] 2016 2016 2016 2016 2016 2016 2016 2016 2016 2016 ... As you can see, each data.frame object contained in the list has been renamed. You can thus access them with the $ operator: 8.3 Generating Pdf or Word reports with R 8.4 Scraping the internet 8.5 Writing your own package 8.6 Random tips and tricks 8.6.1 Creating a log file "],
["references.html", "References", " References "]
]
